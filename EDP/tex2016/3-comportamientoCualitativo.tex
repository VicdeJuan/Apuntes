% -*- root: ../EDP2016.tex -*-
\chapter{Comportamiento cualitativo}

% clase 15/3/2016

En este capítulo vamos a ver:

\begin{itemize}

	\item Ondas (hiperbólica)
	\item Calor (parabólica)
	\item Laplace (elípticas)

\end{itemize}


\section{Ondas}

	Hemos visto ya el problema en dimensión 1: la cuerda vibrante.

	Hemos visto también el método de separación de variables que solo nos valdrá en un dominio acotado. Pero, ¿qué podemos hacer en dominios no acotados? ¿Hay más soluciones?.

	Después vimos la fórmula D'Alambert \eqref{eq:DALEMBERT}, que sí que nos sirve para dominios no acotados pero es difícil de interpretar en dominios acotados. Veamos un ejemplo de esta afirmación:

	\begin{example}

		\[\begin{cases}
			u_{tt} - u_{xx} = 0, \ x \in (0,L), \ t > 0 \\
			u(0,t) = u(L,t) = 0, \ t > 0\\
			u(x,0) = f(x) \\
			u_t(x,0) = 0
		\end{cases}\]

		Y tenemos la fórmula a la que llegamos:
		\[ u(x,t) = \frac{1}{2} \{f(x+t)+f(x-t)\} + 0  \]

		Resulta que tenemos una fórmula muy útil pero ocurre que en un dominio acotado no podemos calcular $f$ cerca del borde al realizar $x+t$ ó $x-t$. Tenemos que encontrar una manera de extender $f$ de manera que esté de acuerdo con el contorno. No es lo mismo que una cuerda esté sujeta y la onda se refleje de una manera, a que no esté sujeta.

		\begin{center}
			\begin{tikzpicture}
			\draw[-] (-1,0) -- (3,0);
			\draw[-] (0,-0.5) -- (0,2);


			\draw[dashed] (1.5,0) node [below] {$L$} -- (1.5,1.5);

			\draw[thick, blue] plot[smooth, tension=.9] coordinates{(0.7,0) (0.8,0.2) (1,0.4) (1.2,0.7) (1.5,0.9)};

			\end{tikzpicture}
		\end{center}

	\end{example}

	\subsection{Unicidad y conservación de la energía}

		Uno de los problemas más habituales al tratar las ecuaciones en derivadas parciales es saber si las soluciones son únicas o no. Partimos de nuestro problema
		\[ \begin{cases}
			u_{tt}-u_{xx} = 0\qquad x \in (0,L), t >0 \\
			u(x,0) = f(x)	\\
			u_t(x,0) = g(x) \\
			\text{Datos de contorno Dirichlet, Neumann o periódicos}
		\end{cases} \]

		Supongamos que existen dos soluciones $u_1, u_{2}$. Entonces, tendremos que $u = u_1 - u_2$ será solución del sistema
		\( \begin{cases}
			u_{tt}-u_{xx} = 0\qquad x \in (0,L), t >0 \\
			u(x,0) = 0	\\
			u_t(x,0) = 0 \\
			\text{Datos de contorno}
		\end{cases} \label{eq:Onda:ProblemaUnicidad} \)

		Para comprobar la unicidad, querremos saber si $u \equiv 0$ ($u_1$ y $u_2$ son iguales y la solución es única) o no.

		\begin{figure}[hbtp]
		\centering
		\inputtikz{EnergiaOnda}
		\caption{Una ilustración de las fuerzas que dependen de la velocidad ($\vf_c$) y de la posición ($\vf_p$) que llevan a la definición de energía cinética y potencial.}
		\label{fig:EnergiaOnda}
		\end{figure}

		Para ello, vamos a introducir la ``energía'' de la onda y vamos a ver si nos da algo interesante. En cada punto $x ∈ [0,L]$ vamos a tener dos ``fuentes'' de energía. Una dependerá de la velocidad que lleve un punto, que será la cinética. Mirando a la ecuación de onda, esa velocidad no es más que la derivada de la onda $u$ con respecto al tiempo: si en $t_0 + Δt$ la onda ha crecido entonces llevamos velocidad positiva.

		La otra fuente de energía será la potencial, que depende de la altura $u$ del punto que consideremos. Si nos fijamos de nuevo en la \fref{fig:EnergiaOnda}, de lo que depende es de la derivada con respecto a $x$. En cualquier caso, haciendo un ejercicio de imaginación la expresión de la energía será entonces la suma de ambas a lo largo de toda la cuerda:
		\( E(t) = \frac{1}{2} \int_0^L (u_t)^2 + (u_x)^2 \dif x \label{eq:Onda:Energia} \)

		Podemos derivar esta ecuación con respecto al tiempo, ya que $u ∈ C^2$, y entonces tenemos que  \( E'(t) = \int_{0}^L u_t u_{tt} + u_x u_{xt} \dif x \label{eq:Onda:DerivadaEnergia} \)

		¿Cuánto vale esta derivada? Vamos a verlo calculando la integral de $u_x u_{xt}$:
		\begin{multline}
		\int_0^L \underbracket{u_x}_u \underbracket{u_{xt} \dif x}_{\dif v} = \eval[2]{u_x u_t}_{x= 0}^L - \int_0^L u_{xx} u_t \dif x = \\
		= u_x(L,t) u_t(L, t) - u_x(0,t) u_t(0,t) - \int_0^L u_t u_{xx} \dif x \label{eq:Onda:ContornosIntegral}
		\end{multline}

		Como se puede ver, aquí entran en juego las condiciones de contorno. Recordamos las tres posibilidades que tenemos:

		\begin{itemize}[itemsep = 0pt]
		\item \textbf{Neumann}: $u_x(L, t) = u_x(0,t) = 0$.
		\item \textbf{Dirichlet}: $u(0,t) = u(L, t) = 0 = u_t(0,t) = u_t(L, t)$.
		\item \textbf{Periódicas}: $u(L, t) = u(0,t)$, $u_x(L, t) = u_x(0,t)$, $u_t(L, t) = u_t(0,t)$.
		\end{itemize}

		En cualquiera de los tres casos, lo que vamos a tener va a ser lo mismo: que $u_x(L,t) u_t(L, t) - u_x(0,t) u_t(0,t) = 0$. Sustituyendo eso en \eqref{eq:Onda:ContornosIntegral}, lo que nos quedará será que \[ \int_0^L u_x u_{xt} \dif x = - \int_{0}^L u_t u_{xx} \dif x \] y a su vez esto nos permite resolver la ecuación para la derivada de la energía \eqref{eq:Onda:DerivadaEnergia}:
		\[ E'(t) = \int_0^L u_t \left(u_{tt} - u_{xx} \right) \dif x = 0\]
		simplemente fijándonos en que la ecuación de onda nos dice que $u_{tt} - u_{xx} = 0$.

		Finalmente, a lo que hemos llegado no es más que al tradicional principio de \textbf{conservación de la energía}. En este caso, la energía de la onda se conserva a lo largo del tiempo para la ecuación de onda homogénea, y $E(t) = E(0)$, donde
		\[ E(0) = \frac{1}{2} \int_0^L (u_t)^2 (x,0) + (u_x)^2 (x,0) \dif x = \frac{1}{2} \int_0^L g^2(x)+(f'(x))^2 \dif x \]

		\paragraph{Consecuencias} Una vez que tenemos esto, volvemos a las condiciones iniciales \eqref{eq:Onda:ProblemaUnicidad} del problema del que $u = u_1 - u_2$ era solución, en el que los datos iniciales eran $u(x,0) = u_t(x,0)$. Esto nos dice que $E(0) = 0$, y como la energía se conserva tenemos que $E(t) = 0\;∀t ∈ ℝ^+$. Equivalentemente, $0 = \int_0^L (u_t)^2 + (u_x)^2 \dif x$, luego $u_t = u_x = 0$ así que la solución es constante. Finalmente, como el dato inicial era $u(x,0) = 0$, la solución es $u \equiv 0$, luego tenemos \textbf{unicidad}.

			Veamos el caso Dirichlet, pero esto es válido para todos:

			Sean $u_1,u_2 \in C^2$ soluciones del problema
			\[ \begin{cases}
				u_{tt} - u_{xx} = F(x,t)\\
				u(0,t) = \alpha(t), \quad u(L,t) = \beta(t) \\
				u(x,0) = f(x) \\
				u_t(x,0) = g(x)
			\end{cases}\]

			En este problema no tenemos conservación, debido a $\alpha$, $\beta$ y $F(x,t)$ pero podemos transformarlo en un problema de $W$ en donde si tengamos esta propiedad:

			\[\begin{cases}
				W = u_1 - u_2 \\
				W_{tt} - W_{xx} = 0 \\
				W(0,t) = 0 = W(L,t) \\
				W(x,0) = 0 \\
				W_t(x,0)
			\end{cases}\]

			Por conservación de la energía tenemos:
			\[ \int_0^L (W_t)^2 + (W_x)^2 \dif x = 0 \Rightarrow W_t = W_x = 0 \Rightarrow W \equiv \text{cte} \eqreason[\Rightarrow]{$W|_{t=0} = 0$} W(x,t) = 0 \ \forall x\ \forall t \implies u_1 = u_2 \]

			Por lo que hemos obtenido unicidad de las soluciones del problema inicial. Pero aunque sepamos que la solución es única, no sabemos si existe tal solución.

			Volvamos al problema inicial:
			\[ \begin{cases}
				u_{tt} - u_{xx} = F(x,t)\\
				u(0,t) = \alpha(t), \quad u(L,t) = \beta(t) \\
				u(x,0) = f(x) \\
				u_t(x,0) = g(x)
			\end{cases}\]

			Como la ecuación es lineal, podemos sumar y restar cosas. Vamos a buscar una función $C(x,t)$ tal que
			\[ C(0,t) = \alpha(t), \quad C(L,t) = \beta(t) \]

			Por ejemplo: $C(x,t) = \alpha(t) + \frac{x}{L} (\beta(t)-\alpha(t))$

			Consideramos $v(x,t) = u(x,t) - C(x,t)$ (de modo que $v(0,t) = v(L,t) = 0$)

			\[\begin{cases}
				v_{tt} - v_{xx} = u_{tt} - C_{tt} - u_{xx} + C_{xx} = F - C_{tt} + C_{xx} = \gor{F} \\
				v(0,t) = v(L,t) = 0 \\
				v(x,0) = u(x,0) - C(x,0) = f(x) - C(x,0) = \gor{f}(x) \\
				v_t (x,0) = u_t(x,0) - C(x,0) = \gor{g}(x)
			\end{cases}
			\]

			Reescribimos nuestro sistema inicial con $v$ y obtenemos:

			\[ \begin{cases}
				v_{tt} - v_{xx} = \gor{F}(x,t)\\
				v(0,t) = 0, \quad v(L,t) = 0 \\
				v(x,0) = \gor{f}(x) \\
				v_t(x,0) = \gor{g}(x)
			\end{cases}\]

			Tomando $v = H + W$ podemos separar nuestro problema en dos:

			\[ \begin{cases}
					H(x,t) \rightarrow
					\begin{cases}
						H_{tt} - H_{xx} = 0\\
						H(0,t) = H(L,t) = 0 \\
						H(x,0) = \gor{f}(x) \\
						H_t(x,0) = \gor{g}(x)
					\end{cases}\\
					W(x,t) \rightarrow
					\begin{cases}
						W_{tt} - W_{xx} = \gor{F}(x,t)\\
						W(0,t) = 0 = W(L,t) \\
						W(x,0) = 0 \\
						W_t(x,0) = 0
					\end{cases}
				 \end{cases}
			\]

			El sistema de la $H$ ya lo sabemos resolver por separación de variables, Fourier...

			El problema de la $W$ lo resolvemos aplicando Duhamel (método del impulso).
			Buscamos soluciones de la ecuación de ondas homogénea siguiente: \fbox{fijamos $s>0$}
			\[\begin{cases}
				\left.
				\begin{array}{l}
					\Phi_{tt} - \Phi_{xx} = 0 \\
					\Phi(0,t) = \Phi(L,t) = 0 \\
					\Phi(x,0) = 0 \\
				\end{array}
				\right| \text{ separación de variables, Fourier} \\
				\Phi_t(x,0) = \gor{F}(x,s)
			\end{cases}\]

			\textbf{Notación:} $ \Phi = \Phi(x,t,s)$

			Con $\Phi$ denotamos la respuesta al impulso $\gor{F}(x,s)$ que actúa en $t=0$.

			Por tanto, $\Phi(x,t-s,s)$ es a la respuesta al impulso $\gor{F} (x,s)$ que actúa en $t-s = 0$.

			Aplicando {\bf Duhamel}:
			\[ W(x,t) = \int_0^z \Phi(x,t-s,s) ds \]
			Sea
			\[ G(x,t,z) = \int_0^z \Phi(x,t-s,s) ds\]
			\[ G_t = \int_0^z \Phi_t (x,t-s,s) ds \]
			\[ G_z = \Phi(x,t-z,z) \]
			Tenemos que $W(x,t) = G(x,t,t)$
			\[ W_t \eqreason{cambio de variables} G_t + G_z z_t = G_t(x,t,t) + G_z (x,t,t) \cdot 1\]

			\[ W_t(x,t) = \Phi(x,0,t)+ \int_0^t \Phi_t (x,t-s,s) ds\]
			\[ W_{tt} = \Phi_{s} (x,0,t) + \Phi_t(x,0,t) + \int_0^t \Phi_{tt} (x,t-s,s) ds  \]
			\[ W_{xx} = \int_0^t \Phi_{xx} (x,t-s,s) ds \]
			\[ W_{tt} - W_{xx} = \Phi_{s}(x,0,t) + \Phi_t(x,0,t) + \int_0^t \Phi_{tt} - \Phi_{xx}\ ds \]
			\[ W(0,t) = \int_0^t \underbrace{\Phi(0,t-s,s)}_{\equiv 0} ds = 0  \]
			\[ W(L,t) = \int_0^t \Phi(L,t-s,s) ds = 0 \]
			\[ W(x,0) = \int_0^0 \Phi(x,0-s,s) ds = 0 \rightarrow W_t (x,0) = 0 \]
			Nos hemos dejado el lado derecho de la ecuación, que es:
			\[\Phi_s (x,0,t) + \underbrace{\Phi_t(x,0,t)}_{\gor{F}(x,t)} \]
			Finalmente:
			\[ \Phi(x,0,s) = 0, \forall s \Rightarrow \Phi_s (x,0,s) = 0 \ \forall s  \]
			\[ \Phi_t(x,0,s) = \gor{F}(x,s), \forall s \]

			Hemos descompuesto el problema en cuatro problemas más pequeños. Y hemos resuelto cada uno, completándolo con este último. La suma de ellos será una solución del primero, y además sabemos que es única por el resultado obtenido antes.

			Ahora veamos qué pasa con otras condiciones de contorno:
			\[ \begin{cases}
				u_{tt} - u_{xx} = F(x,t)\\
				u(0,t) = \alpha(t),\quad u(L,t) = \beta(t) \\
				u(x,0) = f(x) \\
				u_t(x,0) = g(x)
			\end{cases}\]

			Lo cual cambiamos al problema:
			\[ \begin{cases}
				v_{tt} - v_{xx} = F(x,t)\\
				v(0,t) = \alpha(t),\quad v(L,t) = \beta(t) \\
				v(x,0) = \gor{f}(x) \\
				v_t(x,0) = \gor{g}(x)
			\end{cases}\]

			Y llegamos igual que antes hasta el problema de $W$ ($W = u-v$):
			\[ \begin{cases}
				W_{tt} - W_{xx} = 0\\
				W(0,t) = 0 = W(L,t) \\
				W(x,0) = f - \gor{f} \\
				W_t(x,0) = g-  \gor{g}
			\end{cases}\]
			Por conservación de la energía:
			\[ \frac{1}{2} \int_0^L (W_t)^2 + (W_x)^2 dx = \frac{1}{2} \int_0^L (g-\gor{g})^2 + (f'-\gor{f}\,')^2 dx \]

			Hemos demostrado también dependencia continua de los datos. Lo que quiere decir que datos pequeños nos llevan a energías pequeñas.

			Y por lo tanto acabamos diciendo que el problema de las ondas es un problema bien propuesto: tiene existencia y unicidad de la solución, y dependencia continua de los datos.


			% Clase gjulianm 29/3

		\subsection{Deducción de la ecuación de onda}

		\begin{figure}[hbtp]
		\centering
		\inputtikz{TensionCuerda}
		\caption{Esquema para la demostración, dejando sólo un trozo de cuerda y sustituyendo por la tensión.}
		\label{fig:TensionCuerda}
		\end{figure}

		La idea para la deducción de la ecuación de onda es la siguiente: quitar un tramo de cuerda y sustituirlo por una tensión $T(x,t)$, que representa el efecto del trozo de cuerda a la derecha del punto $x$ en el instante $t$.

		Las componentes horizontales están en equilibrio, luego tienen que anularse: \( T(x+h) \cos (θ(x+h)) - T(x) \cos (θ(x)) = 0 \label{eq:Onda:EquilibrioHorizontal} \)

		Las componentes verticales tienen que seguir la Ley de Newton: \( T(x + h) \sin (θ(x+h)) - T(x) \sin (θ(x)) = m · u_{tt} \label{eq:Onda:LeyNewton} \) donde $m$ es la masa que se calcula a partir de la densidad ρ (constante) y de la longitud de la curva: \[ m = ρ \int_{x}^{x+h} \sqrt{1+u_x^2} \dif s\]

		Para hacer la deducción de la ecuación, dividiremos entre $h$ en \eqref{eq:Onda:LeyNewton}, y haciendo tender $h \to 0$ tenemos la derivada: \[ \left(T(x) \sin θ(x)\right)_x = ρ\sqrt{1+u_x^2(x,t)} u_{tt} \]

		Haciendo el truco de escribir $\sin θ = \cos θ · \tan θ$, tenemos que $\tan θ = u_x$ y nos queda lo siguiente:  \[ \left(T(x) \cos θ(x) \ u_x \right)_x = ρ\sqrt{1+u_x^2(x,t)} \cdot u_{tt} \]

		Ahora derivamos y vemos qué ocurre: \[ \left(T(x) \cos θ(x) \ u_x \right)_x = \left(T(x) \cos θ(x)\right)_x u_x + T(x) \cos θ(x) \ u_{xx} \]

		Podemos simplificar viendo que si dividimos \eqref{eq:Onda:EquilibrioHorizontal}  por $h$ y tomamos límite $h \to 0$, tenemos que $(T(x) \cos θ(x))_x = 0$. Como la derivada es 0, tenemos que $T(x) \cos θ(x)$ es constante.

		Sólo nos falta quitarnos la raíz esa fea. Para ello hacemos la simplificación de tener oscilaciones pequeñas, de tal forma que $u_x$ es pequeño, $u_x^2$ es todavía más pequeño y $1 + u_x^2 \approx 1$. Así, nos queda la ecuación que ya conocemos: \[ u_{tt} - c^2 u_{xx} = 0\]

		\subsection{Ecuación de ondas en $ℝ$}

		Partimos de nuestra ecuación homogénea: \[ \begin{cases}
		u_{tt} - c^2 u_{xx} = 0 \\
		u(x,0) = f(x) \\
		u_t(x, 0) = g(x)
		\end{cases}\]

		La cuestión es que aquí no podemos aplicar las series de Fourier, porque no tenemos una longitud acotada: estamos estudiando la ecuación en todo $ℝ$. Lo que haremos será ver si somos capaces de demostrar que la Fórmula de D'Alembert funciona para este caso. Para eso, hacemos el siguiente cambio de variables: \begin{align*}
		ξ &= x + ct & ξ_x &= 1 & ξ_t &= c \\
		η &= x - ct & η_x &= 1 & η_t &= - c
		\end{align*}

		Haciendo las cuentas tenemos lo siguiente: \begin{align*}
		u_x &= u_ξ + u_η \\
		u_{xx} &= u_{ξξ} + 2 u_{ηξ} + u_{ηη} \\
		u_t &= c u_ξ - c u_η \\
		u_{tt} &= c^2 u_{ξξ} + 2c^2 u_{ηξ} + c^2 u_{ηη}
		\end{align*}

		La conclusión de todo esto es que la ecuación nos queda así: \[ 0 = u_{tt} - c^2 u_{xx} = -4c^2 u_{ηξ} \] de tal forma que la ecuación final nos queda muy simple: \[ u_{ηξ} = 0\]

		De ahí podemos sacar fácilmente que $u_η = α(η)$, una función que sólo depende de $η$. Por tanto, podemos sacar la fórmula para $u$: \[ u = \int α(η) \dif η + B(ξ) = A(η) + B(ξ) = A(x-ct) + B(x+ct)\]

		Si $u(x,0) = f(x)$, entonces $f(x) = A(x) + B(x)$, y si $u_t(x,0) = g(x)$ entonces $g(x) = -cA'(x) + cB'(x)$. El sistema resultante es el siguiente: \[ \begin{cases}
		A' + B' = f \\
		-A' + B' = \dfrac{1}{c} g
		\end{cases} \]

		Resolviéndolo, llegaremos de nuevo a la \concept[Fórmula\IS de D'Alembert]{fórmula de D'Alembert}: \( u(x,t) = \frac{1}{2} \left(f(x + ct) + f(x-ct)\right) + \frac{1}{2c} \int_{x-ct}^{x+ct} g(s) \dif s \label{eq:Onda:DAlembert} \)

		A partir de aquí podemos encontrar algunas consecuencias y estudiar la función de onda. Lo primero es ver que la única solución del problema en todo $ℝ$ viene dada por esta fórmula: no hemos introducido ni quitado nuevas soluciones.

		\begin{figure}[hbtp]
		\centering
		\inputtikz{ReprGraficaEcOnda}
		\caption{{\bf Dominio de dependencia} de la solución (rayado) y {\bf dominio de influencia} de los datos (sombreado).}
		\label{fig:ReprGraficaEcOnda}
		\end{figure}

		Lo siguiente es estudiar lo que se ve en la \fref{fig:ReprGraficaEcOnda}. $u(x,t)$ sólo dependerá de los valores de $f$ en los puntos $a,b$ y del valor de $g$ en el intervalo $(a,b)$. A la región rayada la llamamos el \concept[Dominio\IS de dependencia]{dominio de dependencia} del punto $(x,t)$. La zona sombreada en la figura será el \concept[Dominio\IS de influencia]{dominio de influencia} del intervalo $[a,b]$: es sólo ahí donde influyen los datos de $f,g$ de esos puntos. Por ejemplo, si en $t = 0$ $f = g \equiv 0$ fuera de $[a,b]$, entonces en $t = T$ la solución será cero fuera de $[a - cT, b + cT]$. En otras palabras, hay una velocidad de propagación finita de los datos.

		La aplicación de esto es la demostración de la conservación de la energía. Partíamos de una ecuación \[ E(t) = \frac{1}{2} \int_{-∞}^∞ u_x^2 \dif x + \frac{c^2}{2} \int_{-∞}^∞ u_t^2 \dif x\] y derivando y haciendo cuentas nos salía que \[ E'(t) = \int_{-∞}^∞ u_t(u_{tt} - c^2 u_{xx}) \dif x = 0\] luego la energía se conservaba.

		Ahora bien, cuando hacíamos eso en dominios acotados, lo que necesitamos era la hipótesis de los valores de contorno para poder demostrar que salía lo que tenía que salir. Aquí lo que necesitaremos simplemente es que $f(x)$ y $g(x)$ sean funciones de soporte compacto (son $0$ fuera de un intervalo $[-M, M]$), de tal forma que para tiempos finitos se cumple que en el instante $t$, $u(x,t)$ es $0$ fuera del intervalo $[-M - ct, M + ct]$ y por tanto los términos de borde en la integración por partes para sacar $E'(t)$ se anulan.

		Como nota, no podríamos pedir sólo que $u_x$ y $u_t$ fuesen integrables $L^2$, más que nada porque eso no implica que se vayan a $0$ fuera del intervalo.

		La conservación de la energía nos dará unicidad de solución, también para el problema no homogéneo; y dependencia continua de los datos. Estos resultados habría que compararlos con el teorema en dominios acotados, que es donde lo demostramos en su día.

		\clearpage % FIXME: puede romper el documento
		\subsubsection{Aplicación a ecuaciones en dominios acotados}

		Todo esto que hemos hecho para dominios no acotados se puede aplicar de vuelta a dominios acotados y problemas con reflexiones. Tenemos una cuerda en el intervalo $[0, ∞)$ y nuestro sistema \[ \begin{cases}
		u_{tt} - c^2u_{xx} = 0 & x > 0,\, t ∈ ℝ \\
		u(0,t) = 0 & ∀ t ∈ ℝ \\
		u(x,0) = f(x) & x > 0 \\
		u_t(x,0) = g(x) & x > 0
		\end{cases}\]

		\subsubsubsection{Extensión de los datos}
		El primer método implicará una extensión de los datos a funciones $\tilde{f}, \tilde{g}$ a las que ya veremos qué valor dar cuando $x ≤ 0$, y sacaremos una solución $\tilde{u}$ por la fórmula de D'Alembert \eqref{eq:Onda:DAlembert}. En particular, querremos que $\tilde{u}(0,t) = 0\,∀t ∈ ℝ$. Sustituyendo en la fórmula, \[ 0 = \tilde{u}(0,t) = \frac{1}{2} \left(f(ct) + f(-ct)\right) + \frac{1}{2c} \int_{-ct}^{ct} g(s) \dif s \]

		Para que eso sea 0, necesitamos que $\tilde{f}$ y $\tilde{g}$ sean impares. Así, nuestras extensiones serán \[
		\tilde{f}(x) = \begin{cases}
		f(x) & x > 0 \\
		-f(-x) & x ≤ 0
		\end{cases} \qquad
		\tilde{g}(x) = \begin{cases}
		g(x) & x > 0 \\
		-g(-x) & x ≤ 0
		\end{cases}
		\]

		De ahí sacaríamos la solución $\tilde{u}(x,t)$ y nuestra solución final sería $u(x,t) = \tilde{u}(x,t)$ restringida a $x > 0$.

		\subsubsubsection{Interpretación geométrica. Ley del paralelogramo}
		Sin embargo, tenemos un segundo método de resolución a través de una interpretación geométrica: gracias a la \concept[Ley del paralelogramo]{ley del paralelogramo} podremos sacar el valor de la solución despejando (ver \fref{fig:AplicacionParalelogramo}), sabiendo que \( u(A) + u(C) = u(B) + u(D) \label{eq:Onda:Paralelogramo} \)

		\begin{figure}[hbtp]
		\inputtikz{AplicacionParalelogramo}
		\caption{Para poder obtener los valores cuando sólo sabemos parte de la solución (en este caso, el sombreado azul), podemos usar la regla del paralelogramo, colocando tres puntos en zonas donde sabemos el valor de la solución (uno en el dato inicial, otros dos en la solución calculada) y despejamos para el cuarto punto (en rojo).}
		\label{fig:AplicacionParalelogramo}
		\end{figure}

		Vamos a ver un ejemplo de este método, con la ecuación de siempre y datos iniciales $g \equiv 0$ y \[ f(x) = \begin{cases} 1 & x ∈ [1,2] \\ 0 & x ∈ [0,1) ∪ (2,∞) \end{cases} \]

		Sacando con la regla del paralelogramo los valores tendríamos algo como lo de la \fref{fig:OndaReflexion}, donde la onda rebotaría por la izquierda pero invertida. Además, en la zona donde la onda se anula, la energía se quedaría en la derivada $u_t$, no se nos pierde.

		\begin{figure}[hbtp]
		\centering
		\inputtikz{OndaReflexion}
		\caption{Propagación de la onda con un borde en la izquierda. En las zonas sin sombreado, la onda tiene amplitud nula.}
		\label{fig:OndaReflexion}
		\end{figure}


		Como ejercicios, habría que ver qué ocurre con las ondas en tiempos $t = 2, \frac{3}{4}, \frac{1}{3}$ con $c = 1$. También es interesante ver qué es lo que ocurre cuando $f \equiv 0$ y $g = \ind_{[1,2]}$: el dibujo cambiará de forma esencial.

		El último ejercicio sería ver qué ocurriría con dos bordes. Veríamos los rebotes y las zonas donde las dos ondas que se propagan se juntan.

		\subsubsection{Caso no homogéneo}
		\label{sec:Onda:NoHomogeneo}

		Nos interesa saber qué es lo que ocurre cuando tenemos una fuerza externa, es decir, cuando nuestro sistema es \[ \begin{cases}
		u_{tt} - c^2 u_{xx} = F(x,t) & t ∈ ℝ, \, x ∈ ℝ \\
		u(x,0) = f(x) \\
		u_t(x,0) = g(x) \end{cases}\]

		Recuperando lo que habíamos visto en casos anteriores, lo que haremos será separar en dos sistemas \[ \begin{cases}
		v_{tt} - c^2 v_{xx} =0  & t ∈ ℝ, \, x ∈ ℝ \\
		v(x,0) = f(x) \\
		v_t(x,0) = g(x) \end{cases} \qquad \begin{cases}
		w_{tt} - c^2 w_{xx} = F(x,t) & t ∈ ℝ, \, x ∈ ℝ \\
		w(x,0) = 0 \\
		w_t(x,0) = 0) \end{cases}\]

		Resolviendo ambos sistemas, la solución final será la suma de soluciones. Para el primero usaríamos la fórmula de D'Alembert, y para el segundo vamos a usar el Principio de Duhamel\index{Principio!de Duhamel}. Fijamos $t = τ > 0$, y entonces resolvemos el problema \[ \begin{cases}
		Φ_{tt} - c^2 Φ_{xx} = 0 \\
		Φ(x,0) = 0 \\
		Φ_t(x,0) = F(x,τ) \end{cases}\]

		\begin{wrapfigure}{R}[0.1\textwidth]{0.4\textwidth}
		\centering
		\inputtikz{IntegralOndaNoseque}
		\caption{La integral que hacemos es la del triángulo, con $f$ aportando en los puntos iniciales (verde), $g$ aportando en el intervalo naranja y $F$ en la zona sombreada.}
		\label{fig:Onda:Noseque}
		\end{wrapfigure}

		Así, el impulso $F(x,τ)$ en $t= 0$ sale como \[ Φ(x,t) = \frac{1}{2c} \int_{x-ct}^{x+ct} F(s,τ) \dif τ\] y para $t = τ$ hacemos la traslación \[ Φ(x, t-τ) = \frac{1}{2c} \int_{x-c(t-τ)}^{x + c(t - τ)} F(s, τ) \dif s\]

		De esta forma, la solución para un punto dado es la suma de todos los impulsos a lo largo del tiempo, esto es, \[ w(x,t) = \frac{1}{2c} \int_0^t Φ(x,t-τ) \dif τ = \frac{1}{2c} \int_0^t \int_{x-c(t-τ)}^{x + c(t - τ)} F(s, τ) \dif s \dif \tau \]

		Esta integral es en el fondo lo mismo que integrar en el triángulo de la \fref{fig:Onda:Noseque} con las aportaciones que se comentan. Además, la conservación de la energía nos daría la unicidad de la solución para este problema.

		Ahora nos plantemos como ejercicio el caso en el que solo vibre en vertical, es decir, $u_x(0,t) = 0$. Habría que hacer las extensiones, calculando $\tilde{u}$ y derivando para sacar las condiciones sobre las extensiones. Ahora bien, también se puede pasar a una condición de contorno tipo Dirichlet buscando la solución $v = u_x$, que nos quedaría el sistema de otra ecuación de onda que podemos resolver por la ley del paralelogramo la \fref{eq:Onda:Paralelogramo}\[ \begin{cases} v_{tt} - c^2v_{xx} = 0 \\ v(0,t) = 0 \\ v(x,0) = f'(x) \\ v_t(x,0) = g'(x) \end{cases}\]

		% BOOOOOM.

		\subsection{Estudio de la unicidad mediante la energía}

			Vamos a repasar dos de los problemas de la hoja 3:
			\begin{problem}
				\[\begin{cases}
					u_{tt} - c^2u_{xx} + u_t = 0, \quad x \in (a,b)\\
					u(a,t) = u_x (b,t) = 0\\
					u(x,0) = f(x) \\
					u_t(x,0) = g(x)
				\end{cases}\]
				¿Tenemos unicidad?

				\solution

				Supongamos que tenemos $u_1,u_2$ soluciones:
				\[ \begin{cases} W = u_1 - u2 \\
				W_{tt} - c^2 W_{xx} + W_t = 0 \\
				W(a,t) = W_x (b,t) = 0\\
				W(x,0) = 0\\
				W_t (x,0) = 0
				\end{cases}\]

				Aplicamos el método de la energía:
				\[ 0 = (W_{tt} - c^2 W_{xx} + W_t) W_t\ dx\]

				Si integramos seguimos teniendo 0:
				\[ 0 = \int_a^b (W_{tt} - c^2 W_{xx} + W_t) W_t\ dx\]
				\[ = \int_a^b W_{tt} W_t\ dx - c^2 \int^b_a W_{xx} W_t\ dx + \int_{a}^b W^2_t\ dx  \]

				Tenemos que $W_{tt}W_t \equiv (\frac{1}{2} (W_t)^2)_t $. Además, integrando por partes:

				\[ \int_a^b \underbrace{W_{xx}}_{dv} \underbrace{W_t}_{u} dx = \left. W_x W_t \right|_a^b - \int_a^b \underbrace{W_x W_{tx}}_{(\frac{W_x^2}{2})_t} dx \]
				Observamos que
				\[
				\begin{rcases}
						W_x (b,t) = 0, \forall t\\
						W(a,t) = 0, \forall t \implies W_t (a,t) = 0
				\end{rcases}
				\implies \left. W_x W_t \right|_a^b = 0
				\]

				{\bf Conclusión:}
				\[ E'(t) + \int_a^b W_t^2 dx = 0 \rightarrow \text{ la energía {\bf no} se conserva}\]
				luego
				\[ E'(t) = -\int_a^b W_t^2 dx \leq 0 \]

				Tenemos pues
				\[
					\begin{rcases}
						E \text{ decrece} \\
						E \geq 0 \\
						E(0) \eqreason{en w} 0
					\end{rcases} \implies E \equiv 0 \implies W \equiv 0 \implies u_1 \equiv u_2
				\]

			\end{problem}

			\begin{problem}
				\[\begin{cases}
					u_{tt} - c^2 u_{xx} + hu = F(x,t), \quad x \in \real \\
					u, u_x, u_t \convs[ ][x][±\infty] 0, \forall t\\
					\int_{-\infty}^\infty u_t^2 + c^2 u_x^2 + hu^2 dx < \infty \quad (\forall t) \\
					u(x,0) = f(x) \\
					u_t(x,0) = g(x)
				\end{cases}\]

				¿Hay unicidad?

				\solution

				Supongamos que tenemos $u_1,u_2$ soluciones:
				\[\begin{cases}
					W = u_1 - u_2 \\
					W_{tt} - c^2 W_{xx} + h W = 0\\
					W(x,0) = 0\\
					W_t(x,0)=0
				\end{cases}\]

				Aplicando el método de la Energía:
				\[ 0 = \int_{-\infty}^\infty (W_{tt} - c^2 W_{xx} + h W)W_t\ dx = … \]

				Integrando por partes en $\int\limits_{-\infty}^\infty W_{xx} W_{t}$, los términos de borde se anulan como en el caso anterior:

				\[ … = \int_{-\infty}^{\infty}  \left(\frac{W_t^2}{2}\right)_t dx + c^2 \int_{-\infty}^\infty \left(\frac{W_x^2}{2}\right)_t dx + h \int_{-\infty}^\infty \left(\frac{W^2}{2}\right)_t dx \]

				Con lo que llegamos (usando $hWW_t = h (\frac{W^2}{2})_t$):

				\[ 0 = \left(\int_{-\infty}^\infty  \frac{W_t^2}{2} + c^2 \frac{W_x^2}{2} + h \frac{W^2}{2} dx \right)_t\]

				Integrando obtenemos
				\[ E(t) = \int_{-\infty}^{\infty} \frac{W_t^2}{2} + c^2 \frac{W_x^2}{2} + h \frac{W^2}{2} dx = cte \quad \forall t \]

				Utilizando que la energía inicial es finita, y observando que $E(0) = 0$, podemos deducir que $W \equiv 0$, y por tanto, tenemos unicidad de la solución.

			\end{problem}

			\subsection{Energía y reflexiones}
			Entremos un poco más en detalle con la energía y sus reflexiones en base a lo descrito anteriormente. Tomemos:

			\[\begin{cases}
				u_{tt} - u_{xx} = 0, x > 0 \\
				u(0,t) = 0 \quad \forall t \\
				u(x,0) = f(x) \\
				u_t(x,0) = 0
			\end{cases}\]

			Comenzamos haciendo la extensión impar del dato para ver qué pasa en la región coloreada de la \fref{fig:ReboteExtensionImpar}.
			\begin{figure}[hbtp]
				\begin{center}
				\usetikzlibrary{patterns}
				\begin{tikzpicture}
					\draw[->] (-3, 0) -- (3,0) node[right] {$x$};
					\draw[->] (0, -0.1) -- (0,3.2) node[above] {$t$};

					\draw[thick, blue] (0,0) -- (0,3) node[left] {\tiny $u \equiv 0$};

					\node[label = {below:$1$}] at (1,0) {};
					\node[ label = {below:$2$}] at (2,0) {};
					\node[ label = {below:$-1$}] at (-1,0) {};
					\node[ label = {below:$-2$}] at (-2,0) {};

					\draw[gray] (2,0) -- (-1,3);
					\draw[gray] (1,0) -- (-1,2);
					\draw[gray] (-1,0) -- (1,2);
					\draw[gray] (-2,0) -- (1,3);

					% dashed lines
					\draw[gray,dashed] (1,0) -- (3,2) ;
					\draw[gray,dashed] (2,0) -- (3,1) ;

					\draw[gray,dashed] (-2,0) -- (-3,1);
					\draw[gray,dashed] (-1,0) -- (-2,1);

					% colored regions in x axis
					\fill[pattern = north east lines, pattern color = red] (1, -0.05) rectangle (2, 0.05);
					\fill[pattern = north east lines, pattern color = blue] (-2, -0.05) rectangle (-1, 0.05);

					% Colored square
					 \draw[fill, color=purple, opacity=0.25]  (0.5,1.5) -- (0,2) -- (-0.5,1.5) -- (0,1) -- cycle;
					\node[thick, color=purple] at (0,1.5) {$0$};

				\end{tikzpicture}
				\caption{Haciendo la extensión impar, vemos que la región coloreada debe ser 0 por la ley del paralelogramo.}
				\label{fig:ReboteExtensionImpar}
				\end{center}
			\end{figure}

			En la región coloreada tenemos que
			\(u = \frac{1}{2}f(x+t) + \frac{1}{2}\gor{f}(x-t) \label{eq:reflexion-cuadrado0} \) por D'Alambert. Derivando
			\[ u_x = \frac{1}{2} f'(x+t) (x+t)_x + \frac{1}{2} \gor{f}'(x-t)(x-t)_x = \frac{1}{2} \{f' + \gor{f}'\} \eqreason{$t = \frac{3}{2}$} 0 \]

			Lo que hemos perdido en energía potencial, lo hemos ganado en cinética. Eso lo vemos derivando la \fref{eq:reflexion-cuadrado0} respecto a t:
			\[ u_t = \frac{1}{2} f'(x+t) (x+t)_t + \frac{1}{2} \gor{f}' (x-t)(x-t)_t = \frac{1}{2} \{ f'(x+t) - \underbrace{\gor{f} (x-t)}_{=-f} \} \eqreason{$t = \frac{3}{2}$} f'  \]

			% No he copiado la explicación especial que dió sobre funciones no derivables TODO

			\obs Esta definición que viene ahora no entra y viene acompañada de un ejemplo que no se ha incluido aquí.

			\clearpage % FIXME: puede romper la estructura del documento
			\begin{defn}[Derivada\IS débil]

				G es la derivada débil de $F$ si y solo si:

				\[ \int_{-\infty}^\infty G\Phi dx = -\int_{-\infty}^\infty F \Phi' dx, \ \forall \Phi \in C^1, \ \Phi \text{ con soporte compacto} \]

				\begin{itemize}
					\item $F$ derivable (clásico) $\Rightarrow F'$ es su derivada débil.
					\item A veces la derivada débil existe aunque $F$ no sea derivable en el sentido clásico.

				\end{itemize}
			\end{defn}

			Vamos entonces a ver qué diferencias habría en el caso de una cuerda de guitarra, entre darle un golpe a la cuerda y tocarla:

			\[\begin{cases}
				u_{tt} -u_{xx} =0, \quad x \in \real \\
				u(x,0) = f \\
				u_t(x,0) = g
			\end{cases}\]

			Aplicamos la fórmula de D'Alembert: \index{Fórmula!de D'Alembert}
			\[ u(x,t) = \frac{1}{2} \{ f(x+t) + f(x-t) \} + \frac{1}{2} \int_{x-t}^{x+t} g(s) \ ds \]

			Contemplamos varios casos:

			\begin{figure}[hbtp]
				\begin{minipage}[m]{.5\linewidth}
					\inputtikz{f-neq-0-g-eq-0}
					\captionof{figure}{$f \neq 0, g = 0$}
				\end{minipage}
				\begin{minipage}[m]{.5\linewidth}
					\inputtikz{f-eq-0-g-neq-0}
					\captionof{figure}{$f=0, g \neq 0$}
				\end{minipage}
			\end{figure}



	% Clase 5-4-2016

	\section{Ecuación de Laplace. Laplaciano}

	Si nos fijamos en la ecuación del calor, para dimensión espacial $N$ nos queda que \[ u_t - (u_{x_1x_1} + u_{x_2x_2} + \dotsb + u_{x_N x_N}) = 0\]

	Para la ecuación de ondas, tenemos algo parecido:  \[ u_{tt} - (u_{x_1x_1} + u_{x_2x_2} + \dotsb + u_{x_N x_N}) = 0\]

	Ese último paréntesis es una operación en si misma, que llamaremos el \concept{Laplaciano}: \( Δu = \sum_{i=1}^N u_{x_i x_i} = \tr (\Dif^2 u) = \dv (\grad u) \label{eq:Laplaciano}\)

	Es especialmente interesante verlo como la divergencia del gradiente, para después poder aplicar en un futuro el teorema de Gauss para poder integrar.

	Una forma de utilizarlo es como herramienta para estudiar casos estacionarios de la ecuación de ondas o del calor. Por ejemplo, si nos fijamos en el típico experimento de hacer vibrar una membrana con el sonido, estaríamos ante una ecuación
	\[ \begin{cases}
		u_{tt} - u_{xx} - u_{yy} , \quad (x,y) \in [0,1) \times (0,1) \equiv Q\\
		\restr{u}{∂Q} = 0 \\
		u(x,y,0) = f(x) \\
		u_t(x,y,0) = g(x)
		\end{cases}
	\]

	Podríamos aplicar entonces el método de separación de variables, buscando dos funciones cuyo producto sea la solución: \[ u(x,y,t) = Φ(x,y) T(t) \] de tal forma que \[ \frac{T''}{T} = \frac{ΔΦ}{Φ} = λ, \quad \lambda \in \real \]

	La resolución en $Φ$ nos daría un problema de autovalores: \[ \begin{cases} ΔΦ = λ Φ \\ \restr{Φ}{∂Q} = 0 \end{cases} \] El resultado sería una sucesión de autovalores $λ_k$ y autofunciones $Φ_k$. Resolviendo el problema de $T'' = \lambda T$, y multiplicando las soluciones de ambos problemas, tendríamos la solución en forma de serie
	\[ u(x,y) = \sum_k a_k \ T_k(t) \Phi_k(x,y) \]
	Volviendo al caso de la membrana, si ponemos arena en la membrana se quedará con una forma, más concretamente en los nodos de la membrana: los puntos en los que no vibra. La forma dependerá de los $a_k$ que dependen de los datos iniciales $f, g$, y concretamente, la forma dependerá del $a_k$ que acompañe a la autofunción dominante.

	Nosotros no veremos el problema de resolver el laplaciano para dominios arbitrarios porque necesitamos mucho análisis funcional y en este curso no da tiempo. Nos vamos a centrar en dominios acotados, y vamos a desarrollar varias herramientas que nos permitan inferir cosas sobre la solución a partir de la ecuación.

	\subsection{Funciones armónicas, subarmónicas y superarmónicas}

	\noindent Podemos clasificar las soluciones en tres clases posibles según el signo del laplaciano.

	\begin{defn}[Función\IS armónica] $u$ es armónica en $\Omega$, si $-Δu = 0$ en Ω.
	\end{defn}

	\begin{defn}[Función\IS subarmónica] $u$ es subarmónica en $\Omega$, si $-Δu ≤ 0$ en Ω.
	\end{defn}

	\begin{defn}[Función\IS superarmónica] $u$ es superarmónica en $\Omega$, si ${-Δu ≥ 0}$ en Ω.
	\end{defn}

	En dimensión uno, las funciones armónicas son lineales, las subarmónicas convexas y las superarmónicas cóncavas.

	En dimensiones superiores, las cosas se complican un poco más. Por ejemplo, una función lineal sigue siendo armónica, pero $u(x,y) = x^2 - y^2$ también es armónica.

	\begin{example}
		Un ejemplo de función subarmónica es un paraboloide en dimensión $N$: \[ u(x_1, \dotsc, x_N) = \norm{\vx}^2 = x_1^2 + \dotsb + x_N^2 \] es subarmónica ya que $-Δu = -2N$.
	\end{example}

	\begin{example}
		En dimensión $2$, la función \[ F(x,y) = \log (x^2 + y^2)\] tiene laplaciano $-ΔF = 0$ en $ℝ^2 \setminus \set{(0,0)}$, por lo que es armónica.
	\end{example}

	\begin{example}
		En dimensión $N > 2$, la función \[ G(\vx) = \frac{1}{\norm{\vx}^{N-2}}\] también es armónica: $-ΔG = 0$ en $ℝ^N \setminus \set{\vec{0}}$.
	\end{example}

	Estos dos últimos ejemplos son las llamadas \concept[Soluciones\IS fundamentales]{soluciones\IS fundamentales}, y ya veremos más tarde por qué se llaman así.

	Las funciones armónicas tienen unas propiedades básicas.

	\begin{prop} \label{prop:PropsFuncArmonicas} Sean $u,v$ funciones armónicas en $Ω$.
	\begin{enumerate}[itemsep = 0pt]
	\item La suma $u +v$ es armónica.
	\item El producto por un escalar $\lambda$,  $\lambda u$ es armónica.
	\item El producto $uv$ en general no es armónico.
	\item La traslación $u(x-x_0)$ es armónica en $\set{x \tq x - x_0 ∈ Ω}$.
	\item El escalado $u(kx)$ es armónica en $\set{x \tq kx ∈ Ω}$.
	\item Dada una transformación lineal $\appl{A}{ℝ^N}{ℝ^N}$ con $\norm{Ax} = \norm{x}\;∀x ∈ ℝ^N$ (isometría), entonces $u(Ax)$ es armónica en $\set{x \tq Ax ∈ Ω}$.
	\item \concept{Transformada\IS de Kelvin} La función \[ K(\vx) = \frac{1}{\norm{\vx}^{N-2}} u\left(\frac{\vx}{\norm{\vx}^2}\right) \] es armónica en $\set{ \vx \tq \frac{\vx}{\norm{\vx}^2} ∈ Ω}$.
	\end{enumerate}
	\end{prop}

	La transformada de Kelvin es especialmente importante, ya que lleva de puntos de dentro de una bola a puntos fuera, y permite estudiar lo que pasa en el centro de la bola (en el $0$) viendo lo que ocurre en el infinito. La cuenta es un poco infernal, y nosotros lo haremos sólo en un caso.

	\obs en dimensión 2: \quad $\norm{x}^{N-2} \leftrightarrow log(x^2 + y^2)$

	\begin{proof}[Transformada de Kelvin - $u$ radial]
	Suponemos que $u$ es radial, esto es, que $u$ sólo depende de la norma del vector $\vx$. Diremos entonces que $u \equiv u(r)$ con $r = \norm{\vx}$.

	Vamos a estudiar la ``armonicidad'' de la función.

	Primero calculamos la derivada $r_i$: \begin{align*}
	r^2 &= x_1^2 + \dotsb + x_N^2 \\
	2rr_{x_i} &= 2x_i \\
	r_{x_i} &= \frac{x_i}{r}
	\end{align*}

	Con esto ya podemos calcular la segunda derivada de $u$: \begin{align*}
	u_{x_i} &= u_{r} r_{x_i} = u_{r} \frac{x_i}{r} \\
	u_{x_ix_i} &= \dotsb = \left(\frac{u_r}{r}\right)_r \frac{x_i^2}{r} + \frac{u_r}{r}
	\end{align*}

	Así, el laplaciano queda que es igual a \[ Δu = \sum_{i=1}^N u_{x_i x_i} = \left(\frac{u_r}{r}\right)_r · r + N\frac{u_r}{r} = \dotsb = u_{rr} + \frac{N-1}{r} u_r \]

	El ejercicio a cargo del lector consistiría en ver que dada la transformada de Kelvin \[ H(r) = \frac{1}{r^{N-2}} u\left(\frac{1}{r}\right)\] entonces \[ H_{rr} + \frac{N-1}{r} H_r = 0\]

	\end{proof}

	¿Cómo se escribiría la transformada de Laplace si dependiese también del ángulo? En ese caso, cada punto $\vx ∈ ℝ^N$ se escribiría como $\vx = r · ω$, con $r ∈ [0, ∞)$ y $ω ∈ \crc[N-1]$, de tal forma que el laplaciano sería \[ Δu(\vx) = u_{rr} + \frac{N-1}{r} u_r + \frac{1}{r^2} Δ_{\crc[N-1]} u \] donde $Δ_{\crc[N-1]}$ sería el \concept{Operador\IS de Laplace-Beltrami} que es la restricción del laplaciano a la esfera. Esta sería la conexión de esto con la geometría y no vamos a ver nada más de esto.

	\subsection{Propiedades fundamentales: Principios del máximo y de la media}

	El principio del máximo nos dice lo siguiente: si tenemos una cuerda en equilibrio (una función armónica), no tenemos ni máximos ni mínimos fuera de la frontera. Si, por ejemplo, tenemos ondas en una membrana, entonces no está en equilibrio: está vibrando.

	Podemos mirarlo desde otro lado, tomando una función superarmónica con ${-Δu = F ≥ 0}$. Es decir, que hay un equilibrio en presencia de una fuerza externa $F$. Esta fuerza será positiva si actúa hacia arriba, y negativa si lo hace hacia abajo. El principio del máximo nos dirá que, respectivamente, sólo será posible una onda hacia arriba $u > 0$ o hacia abajo $u < 0$.

	\begin{figure}[hbtp]
		\begin{minipage}[m]{.5\linewidth}
			\inputtikz{ConservacionSignoPostivo}
		\end{minipage}
		\begin{minipage}[m]{.5\linewidth}
			\inputtikz{ConservacionSignoNegativo}
		\end{minipage}
		\caption{$F$ tiene el signo de $u$}
		\label{fig:conservacionSigno}
	\end{figure}

	\begin{prop}[Principio\IS del máximo débil] \label{prop:PrincipioMaximoDebil} Sea $Ω$ un dominio\footnote{Conjunto abierto y conexo} acotado en $ℝ^N$, y sea $u$ una función subarmónica en $Ω$ y $u ∈ C^2(Ω) ∩ C(\adh{Ω})$. Entonces el máximo en el cierre es igual al máximo en la frontera: \[ \max_{\adh{Ω}} u = \max_{∂Ω} u \]
	\end{prop}

	El principio del máximo débil sí que nos permite casos en los que el máximo se alcanza en la frontera y también en el interior. Con artillería más fuerte veremos que estos casos, en la práctica, no son posibles; aunque para ello tendremos que esperar un poco.

	\begin{proof}

	\proofpart{$-Δu < 0$ en Ω (desigualdad estricta)}

	Haremos la demostración por reducción al absurdo: supongamos que $\max_{\adh{Ω}}$ se alcanza en ${x_0 ∈ \mop{int} Ω}$. En ese punto de máximo tiene que pasar dos cosas: que el gradiente se anula ($\grad u = \vec{0}$) y que el hessiano $\Dif^2 u$ tiene que ser semidefinida negativa. Esto es, los autovalores de $\Dif^2 u$ tienen que ser menores o iguales que $0$.

	En ese caso, la traza ha de ser menor o igual que cero, es decir ${\tr \Dif^2 u(x_0)} = {Δu(x_0) \leq 0}$, contradicción porque habíamos dicho que $-Δ u < 0$.

	\proofpart{$-Δu ≤ 0$ en Ω (desigualdad no estricta)}

	En este caso miraremos una función modificada $v_ε \approx u$, tal que $-Δv_ε < 0$. Tomaremos entonces \[ v_ε(\vx) = u(\vx) + ε\norm{\vx}^2\] de manera que \[ -Δv_ε (\vx) = -Δu(\vx) - ε Δ(\norm{\vx}^2) = -Δu(\vx)  - 2εN < 0 \]

	Aplicamos entonces el caso anterior a $v_ε$, y entonces hacemos tender $ε \to 0$. Esto queda como ejercicio para el lector. En el paso al límite, tendremos que aceptar la desigualdad no estricta, lo que nos da la debilidad de este principio.
	\end{proof}

	Aunque este principio lo hemos hecho sólo para funciones subarmónicas, para demostarlo para funciones superarmónicas sólo hay que cambiar el signo del laplaciano.

	\begin{prop}[Principio\IS del mínimo débil] Sea $Ω$ un dominio acotado en $ℝ^N$, y sea $u$ una función superarmónica en $Ω$ y $u ∈ C^2(Ω) ∩ C(\adh{Ω})$. Entonces el mínimo en el cierre es igual al mínimo en la frontera: \[ \min_{\adh{Ω}} u = \min_{∂Ω} u \]
	\end{prop}

	\obs Para {\bf funciones armónicas}, como son sub y super armónicas, tendremos que {\bf el mínimo y máximo se alcanzan en la frontera}.

	Este principio será muy potente: nos permitirá demostrar unicidad, estimaciones, y muchas más cosas.


	% Clase 6-4-2016
	\subsubsection{Aplicaciones}

	Antes de ir directamente con la prueba y desarrollo de esos principios, vamos a ver de qué nos sirven.

	\begin{prop}[Principio\IS de comparación débil]
		$ $ % hack

		El principio del máximo nos permite comparar dos posibles soluciones si el laplaciano de una es mayor que el de otra.

		Partimos de una función superarmónica que es positiva en el borde:
		\[ \begin{cases}
		- Δ u ≥ 0 & \text{en } Ω \\
		\restr{u}{∂Ω} ≥ 0
		\end{cases} \implies u ≥ 0 \text{ en }\adh{Ω} \]

		Si tenemos otra solución $v$ ``menor'' que $u$ en el sentido de los datos, esto es,
		\[ \begin{cases}
		- Δ u ≥ -Δv & \text{en } Ω \\
		\restr{u}{∂Ω}  ≥ \restr{v}{∂Ω}
		\end{cases} \] podemos restar ambas soluciones y aplicar el principio del máximo para obtener que
		\[ \begin{rcases}
		- Δ u - (-Δv) ≥ 0 & \text{en } Ω \\
		\restr{u-v}{∂Ω} ≥ 0
		\end{rcases} \implies u - v ≥ 0 \implies u ≥ v \text{ en }\adh{Ω} \]
	\end{prop}

		Es decir, que el principio del máximo implicará directamente un {\bf Principio de comparación débil}. Más tarde veremos un principio de comparación fuerte para desigualdades estrictas.

	\begin{prop}[Principio\IS de unicidad de la solución con condiciones Dirichlet]
		Con condiciones de Dirichlet, el principio del máximo nos dará unicidad de la solución.
	\end{prop}
	\begin{proof}
		Partimos del problema
		\[ \begin{cases}
			-\Delta u = F & \text{ en } \Omega \\
			u|_{∂ \Omega} = g  & \text{ Dirichlet}
			\end{cases}
		\]

		Si tenemos $u_1, u_2$ soluciones, tenemos que su resta también es solución del problema
		\[ \begin{cases}
			-\Delta u = 0 & \text{ en } \Omega \\
			u|_{∂ \Omega} = 0 & \text{ Dirichlet}
			\end{cases}
		\] y el principio del máximo nos dice que $u_1 - u_2 = 0$, esto es, que la solución es única.
	\end{proof}
	\obs Más tarde veremos qué que pasa con condiciones Neumann, condiciones de la forma
		\[ \begin{cases}
		-\Delta u = F \\
		\left. \dpd{u}{n}\right|_{∂ \Omega} = g
		\end{cases} \]

	\begin{prop}[Estimación\IS a priori]
		$ $ % hack

		El principio del máximo también nos permitirá sacar unas acotaciones a priori para la solución sin tener que calcularla, sólo a partir de los datos que se nos den en un dominio acotado.
	\end{prop}

		El problema del que partimos es el siguiente:
		\[\begin{cases}
		-\Delta u  = F &\text{ en } \Omega ⊆ \bola_R(0)	 \\
		u|_{∂ \Omega} = g
		\end{cases}\] y supongamos que tenemos las siguientes cotas para $F$ y $g$:
		\[ m \leq F \leq M, \quad \gor{m} \leq g \leq \gor{M} \]

		Querremos aplicar el principio de comparación con una función simple para tener una cota que nos valga para $u$. Definiremos entonces la siguiente función auxiliar
		\[ \Phi(\vx) = A - B \norm{\vx}^2 \] con $A,B ∈ ℝ$. El motivo por el cual escogemos esa función es porque es fácil calcular su laplaciano y que ahora podemos cuadrar fácilmente esos coeficientes.

		Si sacamos el laplaciano de Φ, vemos que tenemos que tomar $B = \frac{M}{2N}$, con $N$ la dimensión del espacio, para que sea mayor que $-Δu$:
		\[ - \Delta \Phi = \dotsb = 2NB \eqreason{$\displaystyle B = \frac{M}{2N}$} M \geq F = -\Delta u \]

		Ahora tenemos que escoger $A$ de manera que $\Phi$ y $u$ estén ordenadas en la frontera (${\Phi|_{\partial \Omega} \geq u|_{\partial \Omega}}$). Elegimos $A = \bar{M} + \frac{M}{2N}R^2$:
		\[ \restr{\Phi(x)}{∂Ω} = A - \frac{M}{2N} \norm{\vx}^2 \eqreasonup[≥]{$\vx ∈ Ω ⊆ \bola_R(0)$} A - \frac{M}{2N} R^2 \eqreason{$A = \gor{M} + \frac{M}{2N} R^2 $} \gor{M} \geq g = u|_{∂\Omega} \]

		Así, la función que nos queda es
		\[ \Phi(\vx) = \gor{M} + \frac{M}{2N} R^2 - \frac{M}{2N} \norm{\vx}^2 \] y ahora podemos aplicar el principio de comparación. Tenemos que
		\[ \begin{cases}
		-\Delta \Phi \geq - \Delta u & \text{ en } \Omega \\
		\Phi |_{∂ \Omega} \geq u|_{∂ \Omega}
		\end{cases} \] luego $Φ ≥ u$ en $\adh{Ω}$. Finalmente, esto es la cota que buscábamos:
		\[ u(\vx) \leq \gor{M} + \frac{M}{2N} (R^2 - \norm{\vx}^2)\qquad \forall \vx \in \Omega \]

		\obs Queda como ejercicio para el atento lector repetir la cuenta para $-u$, para poder acotar $u$ inferiormente.

		\begin{prop}[Dependencia continua de los datos]
		Como último ejemplo de aplicación, podemos ver que tenemos una dependencia continua de los datos, es decir, que si cambiamos un poco los datos la solución también cambia poco. Sean $u_1, u_2$ soluciones respectivas de los problemas
		\[ \begin{cases}
			-\Delta u = F_1 & \text{ en } \Omega \\
			u|_{∂ \Omega} = g_1
			\end{cases}
			\qquad
			\begin{cases}
			-\Delta u = F_2 & \text{ en } \Omega \\
			u|_{∂ \Omega} = g_2
			\end{cases}
		\] con $\norm{F_1 - F_2}_∞ = \sup \abs{F_1 - F_2} < ε$ y $\norm{g_1 - g_2}_∞ < δ$.

		Podemos aplicar ahora la estimación a priori que veíamos en el ejemplo anterior al problema con datos $F_1 - F_2$ y $g_1 - g_2$ y tenemos que $u(\vx) ≤ ε + \frac{δ}{2N}(R^2 - \norm{\vx}^2)$, que es precisamente lo que buscábamos: cambios pequeños en los datos acotan los cambios en las soluciones
	\end{prop}

	Todo está está muy bien, lo que nos dice es que si hay existencia, tenemos unicidad. Sin embargo, no vamos a poder dar un teorema de existencia general.

	\obs Si tomamos la ecuación:
	\[ \begin{cases}
		-\Delta u = 0 \text{ en } \Omega \\
		u|_{\partial \Omega} = g
	\end{cases}\]

	Hay que interpretarlo como una solución estacionaria de una ecuación del calor. El problema es que dependiendo de la forma, puede que no exista punto de equilibrio. Esto se puede ilustrar con lo que se conoce como la \concept{Espina de Lebesgue}.

	\begin{figure}[hbtp]
		\centering
		\begin{minipage}[b]{0.45\linewidth}
			\inputtikz{EspinaDLebesgue-se-funde}
			\caption{Esta espina es demasiado fina y terminará fundiéndose.}
			\label{fig:EspinaDLebesgue-se-funde}
		\end{minipage}
		\begin{minipage}[b]{0.45\linewidth}
			\inputtikz{EspinaDLebesgue-no-se-funde}
			\caption{Esta espina no se funde y lleva a un estado de equilibrio.}
			\label{fig:EspinaDLebesgue-no-se-funde}
		\end{minipage}
		\caption{En rojo las zonas calientes, en azul las frías.}
	\end{figure}

	\subsubsection{Propiedad de la media}

		Una vez vistos ejemplos, vamos con la teoría y la demostración del principio de la media. Empezaremos con el caso fácil, en dimensión $N = 2$.

		\begin{prop}[Propiedad\IS de la media (bolas en $ℝ^2$)] \label{prop:MediaBolaR2} Sea $\bola_R(\va) ⊆ ℝ^2$ la bola de radio $R$ centrada en $\va ∈ ℝ^2$. Consideramos el problema \[
		\begin{cases}
			-\Delta u = 0 & \text{ en } \bola_R(\va) \\
			u|_{∂\bola_R(\va)} = f
		\end{cases}\]

		Entonces, se cumple la propiedad de la media: \[ u(\va) = \frac{1}{2πR} \int_{∂\bola_R(\va)} f \]

		Es decir, el valor de $u$ en el centro de la bola es igual a su valor medio en el borde.
		\end{prop}

		\begin{proof} Sabemos que la solución al problema del laplaciano en $\bola_R$ viene dado por el núcleo de Poisson \eqref{eq:NucleoPoisson}, esto es, \[ u(r, \theta) = \frac{1}{2π} \int_{0}^{2\pi} u(1,s) P_r(\theta-s) \dif{s} = \frac{1}{2\pi} \int_0^{2\pi} u(1,s) \frac{1-r^2}{1 + r^2 - 2r\cos(\theta-s)} \dif{s} \]

		Sustituyendo para $r = 0$, tenemos que \[ u(0,θ) = \frac{1}{2π} \int_0^{2π} u(1,s) \dif s = \frac{1}{2π} \int_{∂\bola_1(\vec{0})} f \]

		Ahora sólo falta tener la solución en una bola de radio $R$ centrada en $\va = (a_1, a_2)$. Para eso hacemos la parametrización \[ \sigma_R (s) = (a + R \cos s , b + R \sin s) \quad s \in [0,2\pi) \] con $\norm{σ_R'} = R$. Entonces ya podemos sustituir y ver que efectivamente sale lo que buscamos: \[ \frac{1}{2πR} \int_{∂\bola_R(\va)} f \dif σ_R = \frac{1}{2πR} \int_0^{2π} f(σ_R(s)) \norm{σ_R'} \dif s = \frac{1}{2π} \int_0^{2π} u(1, s) \dif s  = u(0, θ) = u(\va) \]
		\end{proof}

		A partir de esta propiedad de la media del valor en el borde podemos sacar que también es válido si la media la hacemos sobre todos los valores del interior.

		\begin{prop} \label{prop:MediaBolaInteriorR2} Bajo las mismas hipótesis de la \fref{prop:MediaBolaR2}, tenemos que  \[ u(\va) = \frac{1}{πR^2} \int_{\bola_R(\va)} u(x,y) \dif x \dif y  \]
		\end{prop}

		\begin{proof} Lo primero que miramos es que si $\bola_R(\va) ⊂ Ω$ con $\va = (a_1, a_2)$, entonces $∀ρ ∈ [0,R]$ tendremos igualmente que $\bola_ρ(\va) ⊂ Ω$. Con esto podemor plantear la propiedad anterior para radio ρ e integrar a ambos lados en ρ de $0$ a $R$. Para que todo sea más fácil consideramos el cambio de coordenadas correspondiente, y lo abreviamos como $x(ρ, s)$ y $y(ρ,s)$ (es un cambio típico a coordenadas polares).

		Vamos a ello:
		\begin{align*}
		ρ · u(a,b) &= \frac{1}{2π} \int_0^{2π} u(x(ρ, s), y(ρ,s)) · ρ \dif s \\
		\int_0^R ρ · u(a,b) \dif ρ &= \frac{1}{2π} \int_0^R \int_{0}^{2π} u(x(ρ, s), y(ρ, s)) ρ \dif r \dif s \\
		\frac{R^2}{2} u(a,b) &= \frac{1}{2π} \iint_{\bola_R(\va)} u(x,y) \dif x  \dif y \\
		u(a,b) &= \frac{1}{πR^2} \iint_{\bola_R(\va)} u(x,y) \dif x \dif y \\
		u(a,b) &=  \frac{1}{|\bola_R|} \iint_{\bola_R(\va)} u(x,y) \dif x \dif y
		\end{align*} que es precisamente lo que buscábamos: el valor en el centro es la media de valores en toda la bola.
		\end{proof}

		% Clase 11-4-2016

		Investiguemos un poco más qué pasa en $N > 2$. Realizaremos una prueba apoyada en las identidades de Green y demás teoremas del análisis matemático. El primero será el de Gauss, que pasamos a recordar a continuación.

		\begin{theorem}[Teorema\IS de la divergencia de Gauss] \label{thm:Gauss}
		$ $\\ % hack
		Sea ${Ω ⊂ ℝ^3}$ una región con borde $∂Ω$, y ${\appl{\vf}{Ω}{ℝ^3}}$ un campo vectorial continuo y derivable. Entonces se cumple que \[
			\int_{∂\Omega} \vf \dif S = \int_{Ω} \dv \vf \dif x \dif y \dif z
		\]
		Con dS la {\bf medida de la superficie sobre $\partial \Omega$}.\index{Medida! de una superficie}
		\end{theorem}

		\noindent Recordemos también que la \concept[Divergencia]{divergencia} dado un campo $\vf = (F_1, \dotsc, F_n)$ se calcula así \[ \dv \vf = \pd{F_1}{x_1} + \dotsb + \pd{F_n}{x_n} \] y que la \concept[Integral\IS sobre una superficie]{integral sobre una superficie} con {\bf vector normal exterior unitario} $\vn$ es \[ \int_{∂\Omega} \vf \dif S = \int_{∂\Omega} \pesc{\vf, \vn} \dif S \]

		Este ejemplo nos interesa particularmente porque
		\begin{prop}
			El laplaciano es la divergencia del gradiente, esto es, $Δu = \dv (\grad u)$.
		\end{prop}

		También tendremos la siguiente identidad a partir del Teorema de Gauss, que nos será útil para simplificar los cálculos.

		\subsubsection{Identidades de Green}
		% 1
		\begin{prop}
			Sea $u$ armónica en $\Omega$, entonces
			\[ 0 = \int_\Omega \Delta u \dif \gor{x} = \int_\Omega \dv (\grad u) \dif \gor{x} \eqreason{Gauss} \int_{\partial \Omega} \pesc{\grad u, \vn} \dif S = \int_{\partial \Omega} \pd{u}{\vn} \dif S \]
		\end{prop}
		Donde $\pd{u}{\vn}$ no es más que \concept[Derivada\IS direccional]{la derivada direccional}: \[ \dpd{u}{\vn} = \pesc{\grad u, \vn} = \grad_{\vn} u \]

		% 2
		\begin{prop}[Fórmula\IS de integración por partes] \label{prop:IdGreen2}$ $\\ % hack
			Sean $u \in C^1$, $v \in C^2$, entonces
				\( \int_\Omega u \Delta v \dif \gor{x} = \int_{\partial \Omega} u \pd{v}{\vn} \dif S - \int_\Omega \pesc{\grad u, \grad v} \dif \gor{x} \label{eq:IntegPartesNDim} \)
		\end{prop}
		\begin{proof}
			Necesitaremos un campo vectorial, y nosotros sólo tenemos funciones escalares. Definiremos pues $\vf = u \cdot \grad v = (u v_{x_1}, \dots, u v_{x_n})$. Entonces \( \dv \vf = \pesc{\grad u, \grad v} + u \Delta v \label{eq:proofParts} \) integrando y aplicando Gauss
			\[ \int_\Omega \dv \vf \dif \gor{x} \eqreason{la \fref{eq:proofParts}} \int_{\Omega} \pesc{\grad u, \grad v} + u \Delta v \dif\gor{x} \eqreason{Gauss} \int_{\partial \Omega} \underbrace{u \pd{v}{\vn}}_{\pesc{F, \vn}} \dif S  \]
			despejando
			\[ \int_\Omega u \Delta v \dif \gor{x} = \int_{\partial \Omega} u \pd{v}{\vn} \dif S - \int_\Omega \pesc{\grad u, \grad v} \dif \gor{x} \]
		\end{proof}
		\obs Supongamos $-\Delta u = G$, $v = u$, entonces
		\[ \int_\Omega u G \dif \gor{x} = \int_{\partial \Omega} u \pd{u}{\vn} \dif S - \int_\Omega \norm{\grad u}^2 \dif \gor{x} \]

		% 3
		\begin{theorem}[Identidad\IS de Green] \label{thm:IdGreen}
		$ $\\ % hack
		Sean $u,v ∈ C^2(\Omega)$ con $\Omega ⊂ ℝ^3$. Entonces se cumple que \( \int_\Omega v · Δu - u · Δv \dif \gor{x} = \int_{∂\Omega} v \dpd{u}{\vn} - u \dpd{v}{\vn} \dif S \label{eq:IdGreen} \)
		\end{theorem}
		\begin{proof}
			Aplicar la identidad la \fref{eq:IntegPartesNDim} a $u \Delta v$ y a $v \Delta u$, restar e integrar.
		\end{proof}

		\newpage % FIXME: puede romper el documento
		Con todas estas herramientas ya podremos probar la propiedad de la media:
		\begin{prop}[Propiedad\IS de la media] \label{prop:MediaBola} Sea $\bola_{R}(\va) ⊂ ℝ^N$ una bola $N$-dimensional de radio $R$ centrada en $\va ∈ ℝ^N$, y sea $u$ solución del problema dado por \[
		\begin{cases}
			-\Delta u(\vx) = 0 & x ∈ \bola_R(\va) \\
			u(\vx)|_{∂\bola_R(\va)} = f(\vx)
		\end{cases} \]

		Entonces, se cumple la propiedad de la media: \[ u(\va) = \frac{1}{\abs{∂\bola_R}} \int_{∂\bola_R} u(\vx) \dif σ\] donde $\abs{∂\bola_R(\va)}$ es la medida del borde de la bola (es decir, el área/volumen/loquesea de la hiperesfera de radio $R$).
		\end{prop}

		\begin{proof} Vamos a tratar de aplicar las identidades anteriores. De nuevo, hacemos el mismo truco de definir $\vf = v · \grad u = \left(v u_{x_1}, \dotsc, v u_{x_n}\right)$, de tal forma que la divergencia nos queda $\dv \vf = \pesc{\grad v, \grad u} + v Δ u$.

		Como idea feliz para el caso $N > 2$ (que es el que queremos demostrar, el resto ya lo tenemos) tomaremos $v$ de la siguiente forma (si tuviésemos $N=2$ tomaríamos $\log \norm{\vx}$.): \[ v(\vx) = \frac{1}{\norm{\vx}^{N-2}} = (x_1^2 + \dotsb + x_N^2)^{\frac{2-N}{2}}\]

		Haciendo cuentas, nos salen dos resultados interesantes para el gradiente y el laplaciano (ambos definidos sólo cuando $\vx ≠ \vec{0}$):
		\begin{align*}
		\grad v  &= (2-N) \frac{\vx}{\norm{\vx}^N} \\
		- Δ v &= 0
		\end{align*}

		Ahora trataríamos de aplicar la \nref{thm:IdGreen}, pero tenemos que tener cuidado porque ni $v$ ni su gradiente son continuas en todo $ℝ^n$. Tendremos que quitarnos el punto conflictivo, así que integraremos en $B = \bola_R \setminus \bola_ε$ con $ε > 0$.

		Ahora sí podemos aplicar Green, con la ventaja de que $-Δu = -Δv = 0$ en $B$. Así, nos queda que \[ \int_{∂B} v \dpd{u}{\vn} - u \dpd{v}{\vn} \dif S = \int_{B} v Δu - uΔv = 0 \]

		\begin{wrapfigure}[8]{R}[0.1\textwidth]{0.3\textwidth}
		\centering
		\inputtikz{BolaRBolaEpsilon}
		\caption{Frontera de $B$, con las orientaciones concretas para cada bola.}
		\label{fig:BolaRBolaEpsilon}
		\end{wrapfigure}

		Vamos a hacer la integral sobre la frontera, teniendo en cuenta la orientación de los dos anillos (\fref{fig:BolaRBolaEpsilon}, son orientaciones opuestas). Como esa integral es cero, lo que nos queda es que las integrales sobre cada borde son iguales: \begin{align*}
		0 &= \int_{∂B} v \dpd{u}{\vn} - u \dpd{v}{\vn} \dif S \\
		 \int_{∂\bola_{R}} v \dpd{u}{\vn} - u \dpd{v}{\vn} \dif S &=  \int_{∂\bola_ε} v \dpd{u}{\vn} - u \dpd{v}{\vn} \dif S
		\end{align*}

		Sabiendo que $v = \frac{1}{\norm{\vx}^{N-2}}$, y usando que \[ \pd{v}{\vn} = \pesc{\grad v, \frac{\gor{x}}{\norm{x}}} = (2-N) \frac{1}{R^{N-1}} \quad (< 0 \text{ porque } N > 2) \] resolvemos la integral sobre un borde:
		\[ \int_{∂\bola_R} v \dpd{u}{\vn} - u \dpd{v}{\vn} \dif S_R = \int_{∂\bola_R} \frac{1}{R^{N-2}} \dpd{u}{\vn} \dif S_R - \frac{2-N}{R^{N-1}} \int_{∂\bola_{R}} u \dif S_R \eqreason{Gauss + $-\Delta u \equiv 0$} \frac{N-2}{R^{N-1}} \int_{∂\bola_{R}} u \dif S_R
		\]
		de manera similar, sobre el otro borde
		\[ \int_{∂\bola_\epsilon} v \dpd{u}{\vn} - u \dpd{v}{\vn} \dif S_\epsilon = \frac{N-2}{\epsilon^{N-1}} \int_{∂\bola_\epsilon} u \dif S_\epsilon \]
		Luego llegamos a que
		\[\frac{1}{R^{N-1}} \int_{∂ \bola_R} u \dif S_R = \frac{1}{\epsilon^{N-1}} \int_{∂\bola_\epsilon} u \dif S_\epsilon \]
		Utilizando que $\abs{∂ \bola_R} = \omega_N R^{N-1}$, donde $\omega_N$ es la {\bf medida de una esfera} de radio 1:
		\[ \frac{1}{\abs{∂ \bola_R}} \int_{∂ \bola_R} u \dif S_R = \frac{1}{\abs{∂ \bola_\epsilon}} \int_{∂\bola_\epsilon} u \dif S_\epsilon \]
		Como $u$ es armónica en $\Omega \supset \bola_\epsilon$, entonces $u$ es continua en $\partial \bola_\epsilon$. Luego existen $m_\epsilon, M_\epsilon$ tales que $m_\epsilon = \min\limits_{\partial \bola_\epsilon} u$, $M_\epsilon = \max\limits_{\partial \bola_\epsilon} u$, de manera que $m_\epsilon \leq u \leq M_\epsilon$ en $\partial \bola_\epsilon$.

		Por tanto tenemos que
		\[ m_\epsilon \abs{\partial \bola_\epsilon} \leq \int_{\partial \bola_\epsilon} u \dif S_\epsilon \leq M_\epsilon \abs{\partial \bola_\epsilon} \implies m_\epsilon \leq \frac{1}{\abs{∂ \bola_\epsilon}} \int_{∂ \bola_\epsilon} u \dif S_\epsilon \leq M_\epsilon \]
		Por continuidad: \[M_\epsilon, m_\epsilon \convs[ ][\epsilon][0] u(0) \]

		En \textbf{conclusión}, hemos llegado a lo que buscábamos:
		\[ u(0) = \frac{1}{|\partial \bola_R|} \int_{∂ \bola_R} u(y) \dif S_R \]
		\end{proof}

		Sin demostrarlo, vamos a ver que tenemos algunas desigualdades si $u$ es sólo superarmónica o subarmónica.

		\begin{prop}[Propiedad\IS de la media en esferas para funciones sub/superarmónicas] $ $ \\ % hack
		Si $u$ es subarmónica, entonces tenemos que \[ -Δ u ≤ 0 \implies u(0)  ≤  \frac{1}{|\partial\bola_R|} \int_{∂ \bola_R} u(y) \dif  \sigma_R\]

		Si $u$ es superarmónica, entonces
		\[ -Δ u ≥ 0 \implies u(0)  ≥  \frac{1}{|\partial\bola_R|} \int_{∂ \bola_R} u(y) \dif  \sigma_R\]
		\end{prop}

		Por supuesto, la desigualdad vale para cualquier bola centrada en cualquier punto:
		\[ u(\vx_0) = \frac{1}{|∂ \bola_R(\vx_0)|} \int\limits_{∂\bola_R(\vx_0)} u(y)\ \dif \sigma_R \]

		La propiedad de la media en esferas implica la propiedad de la media en bolas, es decir que también tenemos un resultado análogo al que teníamos en dimensión 2 (\fref{prop:MediaBolaInteriorR2}):
		\begin{prop} \label{prop:MediaBolaInterior} Bajo las mismas hipótesis de la \fref{prop:MediaBola}, tenemos que  \[ u(\va) = \frac{1}{\abs{\bola_R(\va)}} \int_{\bola_R(\va)} u(\gor{y}) \dif \gor{y}  \]
		\end{prop}
		y de manera similar
		\begin{prop}[Propiedad\IS de la media en bolas para funciones sub/superarmónicas] $ $ \\ % hack
		Si $u$ es subarmónica, entonces tenemos que \[ -Δ u ≤ 0 \implies u(x_0)  ≤  \frac{1}{|\bola_R (x_0)|} \int_{\bola_R (x_0)} u(y) \dif \gor{y} \]

		Si $u$ es superarmónica, entonces
		\[ -Δ u ≥ 0 \implies u(x_0)  ≥  \frac{1}{|\bola_R (x_0)|} \int_{\bola_R (x_0)} u(y) \dif \dif \gor{y} \]
		\end{prop}

		La propiedad de la media es también interesante porque nos permitirá probar el principio del máximo fuerte.

		\subsubsection{Principio del máximo fuerte}

		Hasta ahora tenemos unicidad para condiciones de Dirichlet, por el \nref{prop:PrincipioMaximoDebil}. Vamos a demostrar que {\bf tenemos unicidad para el resto de condiciones de contorno}:


		\begin{itemize}
			\item Dirichlet:
				\[ \begin{cases}
					-\Delta u = F \text{ en } \Omega \\
					u |_{\partial \Omega} = g \\
					u_1,u_2 \text{ soluciones} \\
					w = u_1 - u_2
				\end{cases} \]

				Utilizando las identidades de Green:
				\[ 0 = - \int_{\Omega} w \ \Delta w \dif x = - \left\{  \int_{\partial \Omega} \eqreason[w]{= 0} \frac{\partial w}{\partial u} d\sigma - \int_{\Omega}\norm{\grad w}^2 dx \right\}  \]
				\[ 0 = \int_{\omega}\norm{\grad w}^2 dx \implies \grad w \equiv 0 \implies
				\begin{rcases}
					w \equiv cte\\
					w |_{\partial \Omega} = 0
				\end{rcases} \implies w \equiv 0\]

			\item Neumann:
				\[ \begin{rcases}
					-\Delta u = F \text{ en } \Omega \\
					\pd{u}{\vn}|_{\partial \Omega} = g
				\end{rcases} \dots
				\begin{cases}
						- \Delta w = 0 \\
						\pd{w}{\vn}|_{\partial \Omega} = 0
				\end{cases}
				\]
					Haciendo una cuenta similar llegamos a
					\[ \int_{\Omega} \norm{\grad w}^2 dx = 0 \implies \grad w = 0 \implies W = \text{cte.}  \]

					Tenemos unicidad {\bf salvo constantes}.

			\item Mixtas:
			\[ \begin{rcases}
				- \Delta u = F \ \text{ en } \Omega\\
				u + k \pd{u}{\vn}|_{\partial \Omega} = g & k \geq 0
			\end{rcases} \dots
			\begin{cases}
				- \Delta w = 0 \ \text{ en } \Omega\\
				w + k \pd{w}{\vn}|_{\partial \Omega} = 0 & k \geq 0
			\end{cases}\]
			Hacemos las cuentas
			\begin{gather*}
				\int_{\partial \Omega} w \cdot \pd{w}{\vn} \dif \sigma = \int_\Omega \norm{\grad w}^2 \dif x \eqreason[\leftrightarrow]{w = -k \pd{w}{\vn}} \int_{\partial \Omega} (-k) \left(\pd{w}{\vn}\right)^2 \dif \sigma = \int_\Omega \norm{\grad w}^2 \dif x\\
				0 \leq \int_\Omega \norm{\grad w}^2 \dif x \leq 0 \implies \grad w = 0 \implies w = cte
				\eqreason[\implies]{$w + k \pd{w}{\vn}|_{\partial \Omega} = 0$} w \equiv 0
			\end{gather*}
		\end{itemize}
		\obs Si $k < 0$, la prueba no funciona. De hecho, no hay unicidad en ese caso.


		\begin{theorem}[Principio\IS de la media] Sea $u$ una función superarmónica Ω
			\[ - \Delta u \geq 0 \text{ en el dominio } \Omega \]
			entonces
			\[ u (\bar{x}) \geq \frac{1}{|\partial B_R(\bar{x})|} \int\limits_{\partial B_R (\bar{x})} u(\bar{y}) d \sigma_R \quad \forall x \in \Omega, \forall R : B_R(\bar{x}) \subset \Omega \]

		\end{theorem}

		\begin{proof}

			Supongamos que sabemos que $u$ es continua y cumple la propiedad anterior. Intentemos probar que el mínimo se alcanza en la frontera por reducción al absurdo.

			Supongamos que existe $\gor{x}_m \in \text{int } \Omega$ tal que $u(\gor{x}_m) \leq u(\gor{x}) \leq u(\gor{x}), \forall \gor{x} \in \gor{\Omega}$

			Tomamos un $R$ tal que $B_R (\gor{x}_m) \subset \Omega$:
			\[ u(x_m) \geq \frac{1}{|\partial B_R|}  \int\limits_{\partial B_R} u(\bar{y}) d \sigma_R \]
			Si $u(y) \eqreason[>]{estricta} u(x_m)$ para $ y \in \Gamma \subset \partial \bola_R(\gor{x}_m) \subset \Omega$, entonces tendría $$\frac{1}{|\partial B_R|} \int\limits_{\partial B_R} u(y) d \sigma_R > u(x_m) \quad\text{ (porque u es contínua)}$$

			Por tanto $u \equiv u(x_m)$ en todos los puntos de $\partial B_R(x_m)$, para todo $R$ tal que $B_R \subset \Omega$. Es decir, $u \equiv u(x_m)$ en toda la bola $B_R$.

			Como $\Omega$ es conexo, es conexo por caminos. Luego podemos conectar $x_m$ con $x_*$ mediante una curva continua $\Gamma$ contenida en $\Omega$

			% http://tex.stackexchange.com/a/130770
			\begin{minipage}[t]{\linewidth}
				\centering
				\inputtikz{DominioPpioMediaFuerte}
				\captionof{figure}{Ilustración del argumento}
				\label{fig:DominioPpioMediaFuerte}
			\end{minipage}

			Sea $x_1$ un punto en $\Gamma$ que está a distancia $R$ de $x_m$. Podemos repetir el argumento anterior para $x_1$ hasta llegar a $x_*$ en un número finito de pasos.

			¿Cómo sabemos que el radio no tiende a 0 y el número de pasos es finito?

			Sea $\delta = \dist(\Gamma, \partial\Omega)$, distancia entre dos compactos, $\delta>0$,  entonces como $x_1 \in \Gamma$, sabemos que $\bola_\delta(x_1) \subset \Omega$, luego $\delta \leq R$, por tanto siempre avanzamos algo y llegaremos a $x_*$ en un número finito de pasos.

			Por lo tanto $u$ es constante en $\Omega$.
		\end{proof}

		\begin{theorem}[Principio\IS del máximo fuerte]  \label{prop:MaximoFuerte}

			Dado $\Omega$ dominio abierto y conexo.

			\begin{itemize}
				\item $-\Delta u \geq 0$ en $\Omega$ entonces:
				\begin{itemize}
					\item $\min\limits_{\gor{\Omega}} u = \min\limits_{\partial \Omega} u$
					\item Además si $u(x_m) = \min\limits_{\gor{\Omega}} u$ para algún $x_m \in \text{int } \Omega$ entonces $u \equiv$ cte.
				\end{itemize}

				\item $-\Delta u \leq 0$ en $\Omega$:
				\begin{itemize}
					\item $\max\limits_{\gor{\Omega}} u = \max\limits_{\partial \Omega} u$
					\item Además si $u(x_m) = \max\limits_{\gor{\Omega}} u$ para algún $x_m \in \text{int } \Omega$ entonces $u \equiv$ cte.
				\end{itemize}

				\item $-\Delta u = 0$: Entonces se cumplen las dos condiciones anteriores.

			\end{itemize}

		\end{theorem}

		\begin{figure}[hbtp]
			\begin{minipage}[t]{0.33\linewidth}
				\inputtikz{PpioMediaFuerteNo1}
			\end{minipage}
			\begin{minipage}[t]{0.33\linewidth}
				\inputtikz{PpioMediaFuerteNo2}
			\end{minipage}
			\begin{minipage}[t]{0.33\linewidth}
				\inputtikz{PpioMediaFuerteSi}
			\end{minipage}
			\caption{Consecuencias del Principio del Máximo fuerte}
		\end{figure}

		\begin{example}[Dominio no acotado]

			\[\begin{array}{l}
				-\Delta u = 0 \text{ en } \|x\| > 1 \\
				\lim\limits_{\|x\| \to \infty} u(x) = 0 \\
				u|_{\|x\| = 1} = f(x), \text{ con } 1 < f(x) < 2
			\end{array}\]

			Nos hace falta saber qué le pasa a la función en el infinito. El máximo será el máximo de $R=1$ y el mínimo cuando $R$ tiende a 2.

		\end{example}


		\begin{theorem}
		Si $u$ continua y
		\[ u(\gor{x}) = \frac{1}{|B_R|} \int\limits_{B_R(\gor{x})} u(\gor{y})\dif\gor{y} \quad \forall B_R(\gor{x}) \subset \Omega \]
		entonces {\bf $u$ es armónica}.
		\end{theorem}
		\obs Se podría hacer también con el contorno pero sería equivalente.

		\begin{proof}

			¿Como es posible que esa identidad indique que $u \in C^2$. Veámoslo:

			Sea $B_R \subset \Omega$. Consideramos:
			\[ \left. \begin{array}{l}
				- \Delta \Phi = 0 \text{ en } B_R \\
				\Phi |_{\partial B_R = u}
			\end{array} \right\} \Rightarrow \begin{cases}
				\text{ Sabemos resolver en } n = 2 \text{ (Poisson)}\\
				\text{Asumimos que tiene solución para cualquier } N
			\end{cases}
			\]

			Queremos probar que $u \equiv \Phi$ en $B_R$, ya que $\Phi$ es armónica. Como es armónica cumple la propiedad de la media. $u$ también cumple la propiedad de la media, por lo que $\Phi - u$ también. Esto es suficiente para cumplir el principio del máximo y como $\Phi -u = 0$ en la frontera, $\Phi = u$.

		\end{proof}

		\textbf{Otros resultados}

		\begin{itemize}
			\item $u$ armónica $\Rightarrow u$ analítica
			\item Los ceros de una función armónica no pueden ser puntos aislados.
			\item Si $u$ es armónica, $u \equiv 0$ en $B_R$. Entonces $u \equiv 0$.
		\end{itemize}



		% Clase 18-4-2016

		Vamos a enunciar algunos teoremas que se derivan del Principio del Máximo fuerte:

		\begin{theorem}[Teorema\IS de Liouville] $ $\\ % hack
		Sea u función armónica y acotada en $\real^n$, es decir que existe un real $M$ tal que ${-M \leq u(x) \leq M}$, entonces {\bf u es constante}.
		\end{theorem}

		\begin{theorem}[Teorema\IS de Harnack] $ $ \\ %hack
		Sea $u$ una función positiva armónica en una $\bola_R(x_0) \subset \Omega$. Entonces existen constantes positivas $C_1, C_2$ que solo dependen de R, tales que:
		\begin{itemize}
				\item $C_1(R) u(\gor{x}_0) \leq u(\gor{x}) \leq C_2 (R) u(\gor{x}_0), \quad \forall \gor{x} \in B_R(\gor{x}_0)$
				\item $C_1(R)\max\limits_{\gor{B}_R(\gor{x}_0)} u \leq C_2(R) \min\limits_{\gor{B}_R(\gor{x}_0)} u $
			\end{itemize}
		\end{theorem}

		\begin{figure}[hbtp]
			\inputtikz{ThmHarnack}
			\caption{El teorema de Harnack dice que esto {\bf NO} puede pasar.}
			\label{fig:ThmHarnack}
		\end{figure}

		\begin{theorem}[Teorema\IS de Hopf]
			\[ \left. \begin{array}{l} \left. \begin{array}{r}
				-\Delta u \geq 0  \\
				u \geq 0
			\end{array} \right\} \text{ en } \Omega \\
			u(x_0) = 0 \text{ para algún } x_0
			\end{array} \right\} \implies \frac{\partial u} {\partial n} (x_0) < 0
			\]
		\end{theorem}

		\begin{figure}[hbtp]
			\begin{minipage}[t]{0.5\linewidth}
				\inputtikz{Hopf_Consec1}
			\end{minipage}
			\begin{minipage}[t]{0.5\linewidth}
				\inputtikz{Hopf_Consec2}
			\end{minipage}
			\caption{Lo que nos dice el teorema de Hopf}
		\end{figure}

		\clearpage % FIXME: puede romper el documento
		\subsubsection{Conexiones con la energía. Integral de Dirichlet}
		Antes de terminar de hablar de la ecuación de Laplace, volvamos a la integral de Dirichlet:
		\[ u_{tt} - u_{xx} = 0 \rightarrow \text{ Energía: } \frac{1}{2} \int_a^b u_t^2 + u_x^2 \dif x \]

		En dimensión $n$:
		\[ u_{tt}- \Delta u = 0 \rightarrow E \equiv \frac{1}{2}\int\limits_\Omega u^2_t + | \nabla_x u |^2 \dif x \]

		Posición estacionaria: $u = u(x) \rightarrow u_t = 0$

		\[ - \Delta u = 0 \rightarrow \text{ energía potencial: }\quad \int\limits_\Omega | \nabla u|^2 \dif\bar{x} \]

		\begin{proof} $ $\\ % hack
		Idea: La solución es la de energía mínima:

		\[ \begin{cases}
			-\Delta u = 0 \text{ en } \Omega \\
			u|_{\partial\Omega} = g
		\end{cases}\]
		\[ A = \set{ \omega \in C^2(\Omega) / w |_{\partial \Omega} = g } \quad \text{ (funciones admisibles)}\]

		\proofpart{$\implies$}

		Supongamos $u$ solución $\implies$ $u \in A$, y sea $v \in A$:
		\[ 0 = \int\limits_\Omega (-\Delta u)(u-v) \dif\gor{x} = - \int\limits_{\partial\Omega} \pd{u}{\vn} (u \eqreason[-]{$g-g=0$}v) + \int\limits_\Omega \pesc{\nabla u, \nabla (u-v)} \dif\gor{x} \]

		\[ 0 = \int_\Omega \|\nabla u\|^2 \dif\gor{x} - \int_\Omega \pesc{\nabla u, \nabla v} \dif x \]

		Utilizando el siguiente lema:
		\begin{lemma}[Propiedad\IS de Cauchy-Swartz] $ $ \\ % hack
			Todo espacio con un producto escalar ``*'', cumple que
			\[ a * b \leq \|a\| \cdot \|b\| = (a*a)^{1/2} (b*b)^{1/2} \]
		\end{lemma}

		Con siguiente producto escalar: $\displaystyle u * v = \int\limits_{\Omega} \pesc{\nabla u, \nabla v} \dif x $, tenemos que
		\[ \int_\Omega \pesc{\nabla u, \nabla v} \dif x \leq \left( \int_\Omega |\nabla u|^2 \dif x \right)^{1/2} \left( \int_\Omega |\nabla v|^2 \right)^{1/2} \]

		\textbf{Conclusión:}
		\[ \int_\Omega \| \nabla u \|^2 \dif x \leq \left( \int_\Omega |\nabla u|^2 \dif x \right)^{1/2} \left( \int_\Omega |\nabla v|^2 \dif x \right)^{1/2} \]

		Es decir:
		\[ \left( \int_\Omega |\nabla u|^2 \dif x \right) \leq \left( \int_\Omega |\nabla v|^2 \dif x \right) \quad \forall v \in A \]

		Luego la solución implica tener Energía mínima.

		\proofpart{$\Longleftarrow$}

		Para demostrar la implicación en el otro sentido:

		\[ E(\Phi) = \int_\Omega |\nabla \Phi|^2 \dif x \]

		\[ w \in A, \text{ tal que } E(w) \leq E(\Phi), \forall \Phi \in A\]
		\[ w \in A \implies w|_{\partial \Omega} = g\]

		Queremos probar que $-\Delta w = 0$ en $\Omega$.

		Sea $w+t\psi \in A, t \in \real$:
		\[\begin{cases}
			\psi \in C^2(\Omega)\\
			\psi|_{\partial \Omega} = 0
	\end{cases}\]
		\( E(w) \leq E(w + t \psi), \forall t \label{eq:eqEleqEt} \)

		Fijado $\psi$, definimos $g(t) = E(w + t \psi)$, que tiene un mínimo en $t=0$ por la \fref{eq:eqEleqEt}.

		\[E= \int_\Omega | \nabla (w+t\psi)|^2 \dif x = \int_\Omega \pesc{\nabla (w+t\psi), \nabla(w + t \psi)} \dif x\]
		\[ = … = \int_\Omega |\nabla w|^2 \dif x + t^2 \int_\Omega |\nabla \psi|^2 \dif x + 2t\int_\Omega \pesc{\nabla w, \nabla \psi} \dif x \]
		Tenemos que $g'(0) = 0$ por definición. Luego
		\[ g'(t) = 2t \int_\Omega | \nabla \psi |^2 \dif x + 2 \int_\Omega \pesc{\nabla w, \nabla \psi} \dif x \]
		Por tanto
		\[ g'(0) = 2 \int_\Omega \pesc{\nabla w, \nabla \psi} \dif x = 0 \quad \forall \psi \]
		Integrando por partes...
		\[ \int_\Omega -(\Delta w)\psi \dif x = \int_{\partial \Omega} \pd{w}{\vn} \psi - \int_\Omega \pesc{\nabla w, \nabla \psi} \dif x  = 0 \]
		Con el resultado anterior, junto con que $\forall \psi \in C^2$ y $\psi|_{\partial\Omega} = 0$, deducimos que $-\Delta w = 0$ en $\Omega$.

		\textbf{Idea:} Minimizar $E$ en el conjunto $A$:

		Tenemos que $E(\Phi) \geq 0, \forall \Phi \in A$. Si consideramos el conjunto
			\[ \set{ E(\Phi); \Phi \in A} \subset [0, \infty) \]
		Como $[0, \infty)$ está acotado en $\real$, tiene un ínfimo, es decir
		\[ \exists \alpha = \text{inf}\set{E(\Phi) : \Phi \in A} \]
		Pero, ¿se alcanza, es decir, tenemos un mínimo?
		\[ \alpha = \text{inf} \implies \alpha + \frac{1}{n} \text{ no es cota inf.} \]
		\[ \implies \exists w_n \in A \text{ tal que } \alpha \leq E(w_n) < \alpha + \frac{1}{n} \]

		Luego encontramos $\set{w_n} \subset A$. Luego podemos probar sin mucho trabajo que $E(w_n) \rightarrow \infty$
		\[ \begin{rcases*}
			\text{¿} w_n \to w_0 \in A \text{?}\\
			\text{¿} E(w_0) = \alpha \text{?}
		\end{rcases*} \text{ Demostrar la convergencia es difícil.}
		\]

		Entramos en el mundo de la convergencia de funciones. Veremos que $C^2$ no es suficiente y hay que usar espacios de Shobolev, que se sale del curso y se va directo a Análisis Funcional.
		\end{proof}


		\subsubsection{Conexiones con Probabilidad}
		\begin{theorem}[Teorema\IS de la probabilidad total] $ $\\ % hack
		Supongamos que tenemos que $P(A \cup B) = 1$, y $P(A \cap B) = 0$. Entonces
		\[P(C) = P(C|A) P(A) + P(C|B) P(B)\]
		\end{theorem}

		\begin{example}
		Supongamos que tenemos un espacio como el de la \fref{fig:ejemploProb} en el que queremos ver cuál es la probabilidad de que un topo que se mueve de manera aleatoria encuentre la puerta. La probabilidad de acertar depende de la posición inicial, y una vez se llega a un borde se para, de manera que la probabilidad de encontrar la salida una vez llegado al borde será 1 ó 0.

		\begin{figure}[hbtp]
			\begin{minipage}[m]{0.5\textwidth}
			\inputtikz{DotInABox}
			\caption{Espacio}
			\label{fig:ejemploProb}
			\end{minipage}
			\begin{minipage}[m]{0.5\textwidth}
			\inputtikz{EjProbabilidadMovimiento}
			\caption{Probabilidad de moverse en cada dirección}
			\label{fig:ejemploProbDir}
			\end{minipage}
		\end{figure}

		Sea $u(x)$ la probabilidad de encontrar una puerta partiendo de un punto $x$ y parándote cuando llegas a un borde.

		Aplicando el teorema de la probabilidad total:
		\[ u(x,y) = u(x+h,y) \frac{1}{4} + u(x-h,y) \frac{1}{4} + u(x,y+h)\frac{1}{4} + u(x,t-h)\frac{1}{4} \]
		\[ 0 = u(x+h,y) + u(x-h,y)+ u(x,y+h) + u(x,y-h) - 4u(x,y) \]
		\[ 0 = \frac{u(x+h,y) + u(x-h,y) -2u(x,y)}{h^2} + \frac{u(x,y+h) + u(x,y-h) - 2u(x,y)}{h^2} \]

		Cuando $h \to 0$:
		\[ 0 = \frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2} = \Delta u(x,y)\]

		Generalizando a todas las direcciones tenemos:
		\[ u(\bar{x}) = \frac{1}{|S_\epsilon|}\int_{S_\epsilon} u(x_\epsilon) d \sigma_{\epsilon}\]
		¡la propiedad de la media!

		\textbf{Tiempo de parada}

		Otro problema interesante es ver cuánto tarda una partícula en llegar a uno de los bordes.

		\noindent Sea $T(x,y)$ el tiempo hasta la parada partiendo de $x$. Aplicando el teorema de la probabilidad total
		\[ T(x,y) = \frac{1}{4} \{ T(x+h,y) + T(x-h,y) + T(x,y+h) + T(x,y-h) \} + \tau(x,y,h)\]
		% no estoy seguro de lo que representa \tau

		\[ … 0 = \frac{\partial^2\tau}{\partial x^2} + \frac{\partial^2 \tau}{\partial y^2} + \lim_{h \to 0} \frac{\tau(x,y,h)}{4h^2} \eqreason{Si $\tau = F(x,y) h^2$} \Delta T + \frac{F}{4} \]

		Y llegamos a
		\[ \begin{cases}
			-\Delta T = F \\
			T |_{\partial \Omega} = 0
		\end{cases}\]
		\end{example}
		\obs Hemos operado con T como si fuese una función, pero es una variable aleatoria. Esta ecuación obtenida es una ``ecuación estocástica''. Al calcular esperanzas llegamos a modelos deterministas (funciones).

%Clase 19-4-2016

\newpage %FIXME: Puede romper el documento
\section{Ecuación del Calor}

	Hemos observado este problema en un dominio acotado (con dimensión espacial 1). Y hemos obtenido diversos resultados como la separación de variables, construcción de series, convergencia… En este último caso hemos obtenido regularidad para $t > 0$ (factor $e^{-\left(\frac{k \pi}{L}\right)^2 t}$).

	Ahora vamos a intentar obtener resultados sobre unicidad (en dimensión 1) y vamos a intentar ver qué pasa cuando el dominio no está acotado o cuando aumentamos el número de dimensiones.

	Veamos un ejemplo concreto. Dado el sistema \[ \begin{cases}
		u_{t} - u_{xx} = 0, x \in (0,L), t > 0 \\
		u(x,0) = f(x) \\
		u(0,t) = u(L,t) = 0 \leftarrow \text{Dirichlet homogéneas}
	 \end{cases}\]

	 \begin{quote}
		La ecuación del calor es el modelo de las ecuaciones de tipo parabólico.
	 \end{quote}

	 Fijamos $T > 0$ y consideramos $Q_T = [0,L]\times [0,T] \in \real^2$, lo cual es un \concept[Cilindro Parabólico]{cilindro parabólico}.

	 Con la varilla entre dos bloques de hielo, lo que esperamos es que la temperatura de la varilla baje y que tengamos temperaturas mínimas en los extremos. Si resulta que la varilla está más fría que el hielo, el proceso contrario ocurrirá y se calentará. En este caso, el mínimo se debería alcanzar en algún punto del instante inicial y los máximos estarían en los extremos. Lo que podemos ver es que no es razonable pensar que los mínimos y máximos van a estar en algún punto que no sea los extremos de la varilla, o en algún punto de la varilla en el instante inicial.

	 \begin{figure}[hbtp]
	 \centering
	 \inputtikz{EcCalorMaximosMinimos}
	 \caption{Máximos y mínimos en la ecuación del calor: no podemos tenerlos por el medio, sólo en los bordes laterales (verdes) y en el inferior (morado), lo que llamaremos la frontera parabólica.}
	 \label{fig:EcCalorMaximosMinimos}
	 \end{figure}

	 Esto nos va a llevar a un principio del máximo algo más fuerte que nos va a restringir en qué partes de la frontera se va a alcanzar.

	 \begin{defn}[Frontera\IS parabólica] \label{def:FronteraParabolica}
		\[\partial_P Q_T = \{(x,0), x \in [0,L]\} \cup \{(0,t), t \in [0,T]\} \cup \{(L,t), t \in [0,T]\}\]
	 \end{defn}

	 \begin{theorem}[Principio\IS del máximo débil] \label{thm:MaximoDebilCalor} Consideramos el siguiente problema de la ecuación del calor:
		\[ \begin{cases}
			u_{t} - u_{xx} = 0, x \in (0,L), t > 0 \\
			u(x,0) = f(x) \\
			u(0,t) = \alpha(t) \\
			u(L,t) = \beta(t)
		\end{cases}\]

		Entonces $u(x,t)$ alcanza su máximo y su mínimo en puntos de la \nlref{def:FronteraParabolica} $\partial_P Q_T$.
	 \end{theorem}

	 \begin{proof}
		Demostraremos por reducción al absurdo distinguiendo dos casos: si el máximo $(x_0, t_0)$ se alcanzase en algún punto del interior o en la parte de la frontera que no es la parabólica (la línea gris de arriba en la \fref{fig:EcCalorMaximosMinimos}). En el primer caso tenemos que $t_0 < T$ y en el segundo $t_0 = T$ (estamos en el borde).

		En ambos casos tendremos que la derivada en $x$ se anula, y la segunda derivada es no positiva. Si estamos en el interior, será además obligatorio que la derivada en tiempo se anule. Si estamos en el borde ($t_0 = T$), la derivada no tiene por qué anularse: puede ser creciente y que simplemente sea un máximo porque ``cortamos'' ahí la región.  Es decir, que tenemos las dos posibilidades siguientes:
		\begin{gather}
		t_0 < T \implies \begin{cases} u_t(x_0, t_0) = 0 \\ u_{xx} (x_0, t_0) ≤ 0 \end{cases}
		\nonumber \\
		t_0 = T \implies \begin{cases} u_t(x_0, t_0) ≥ 0 \\ u_{xx} (x_0, t_0) ≤ 0 \end{cases}
		\label{eq:Calor:MaximoDebil:Casos}
		\end{gather}

		Si tuviésemos una desigualdad estricta en $u_{xx}$ tendríamos la contradicción buscada, ya que entonces no se cumpliría la ecuación $u_{t} - u_{xx} = 0$. Pero no la tenemos, así que tenemos que trabajar un poco más.

		La idea será modificar $u$ para obtener en alguna parte desigualdad estricta. Definimos $v^ε(x,t) = u(x,t) + εx^2$, y vamos a calcular sus derivadas:
		\begin{align*}
			v^\epsilon_t &= u_t \\
			v^\epsilon_{xx} &= u_{xx} + 2\epsilon
		\end{align*}

		Sustituyendo en la ecuación $u_{t} - u_{xx} = 0$, tenemos una nueva ecuación algo más interesante: \[ v^ε_t - v^ε_{xx} = -2ε < 0 \]

		Repitiendo el razonamiento de \eqref{eq:Calor:MaximoDebil:Casos} con $v^\epsilon$ demostramos que $v^\epsilon$ no puede tener máximo en el interior ni en $\partial Q_T - \partial_P Q_T$. Así, para $v^ε$ tenemos que $$ v^ε(x,t) ≤ \max_{∂_PQ_T} v_ε $$
		Como $v^ε \to u$ uniformemente y $u ≤ v^ε$, hacemos tender $ε \to 0$ y lo que nos queda es que \[ u(x,t) ≤ \max_{∂_PQ_t} u \] que es precisamente lo que buscábamos. Si quisiésemos hacer la demostración con el mínimo se haría de manera análoga tomando $\gor{u} = - u$.
	 \end{proof}

	 Como consecuencias de este principio del máximo tenemos, al igual que para la ecuación de onda, los siguientes principios:
	 \begin{itemize}[itemsep = 0pt]
		\item Comparación.
		\item Unicidad.
		\item Estimación a priori.
		\item Dependencia continua de los datos.

	 \end{itemize}

	 Vamos a verlos con ejemplos.

	 \begin{example}[Comparación]
		\begin{align*}
			u_t - u_{xx} = F_1(x,t) &\geq F_2(x,t) = v_t - v_{xx} \\
			u(x,0) = f_1(x) &\geq f_2(x) = v(x,0) \\
			u(0,t) = \alpha_1(t) &\geq \alpha_2(t) = v(0,t)\\
			u(L,t) = \beta_1(t) &\geq \beta_2(t) = v(L,t)
		\end{align*}

		\textbf{Comentarios}
		\begin{itemize}
			\item Resultado válido en dim N, ecuación $u_t - \Delta u = 0$
			\item \[u_t - u_{xx} \geq 0 \quad\text{ (supersolución)}\]
				\[ \underbrace{\min u}_{Q_T} = \underbrace{\min u}_{\partial_P Q_T} \]

				\[u_t - u_{xx} \leq 0 \quad\text{ (subsolución)}\]
				\[ \underbrace{\max u}_{Q_T} = \underbrace{\max u}_{\partial_P Q_T} \]

				Sea $W = u-v$, tenemos
				\begin{gather*}
				\begin{rcases}
					W_t - W_{xx} \geq 0\\
					W(x,0) \geq 0 \\
					W(0,t) \geq 0 \\
					W(L,t) \geq 0
				\end{rcases}
				\implies W \geq 0 \text{ en } \partial_p Q_T \implies \min\limits_{\partial_p Q_t} W \geq 0 \implies\\
				\implies \min\limits_{Q_T} W \geq 0 \implies W \geq 0 \text{ en } Q_T \implies u \geq v \text{ en } Q_T
				\end{gather*}
				%\quad
				%\eqreason[\implies]{Ppio del máximo} W= 0 \text{ en } Q_T \implies u \geq v \text{ en } Q_T
		\end{itemize}

	 \end{example}

	 \begin{example}[Unicidad] Como siempre, consideramos $u_1, u_2$ soluciones del mismo problema, de tal forma que $v = u_1 - u_2$ es solución de \[ \begin{cases} v_t - v_{xx} = 0 \\ \restr{v}{∂_PQ_T} = 0 \end{cases} \]

	Como el máximo y mínimo se alcanzan en la frontera, tenemos que $v = 0$ en $Q_T$. La cuestión es que esto sólo nos vale para condiciones de contorno de este tipo. En la \fref{sec:Calor:Unicidad} veremos un resultado para condiciones de contorno más genéricas.
	 \end{example}

	\newpage %FIXME: Puede romper el documento
	 \begin{example}[Estimación a priori]

		\[\begin{cases}
			u_{t} - u_{xx} = F(x,t) \\
			u(x,0) = f(x) \\
			u(0,t) = \alpha(t) \\
			u(L,t) = \beta(t)
		\end{cases}\]

		Supongamos $|F(x,t)| \leq M, \forall(x,t) \in Q_T$

		Definimos $W(x,t) = u(x,t) + \frac{M}{2} x^2$

		\[ W_t = u_t ; W_{xx} = u_{xx} + M\]
		\[\begin{cases}
			W_t - W_{xx} = u_t - u_{xx} - M = F-M \eqreason[\leq]{$F \leq M$} 0 \quad \text{ (subsolución)}\\
			W(x,0) = u(x,0) + \frac{M}{2} x^2 = f(x) + \frac{M}{2} x^2 \leq \underbrace{f(x) + \frac{M}{2}L^2}_{\|f\|_\infty = \max |f|}\\
			W(0,t) = u(0,t) = \alpha(t) \\
			W(L,t) = u(L,t) + \frac{M}{2}L^2 = \beta(t) + \frac{M}{2} L^2
		\end{cases}\]
		Donde las últimas tres ecuaciones son la frontera parabólica del cilindro parabólico de W. Luego tenemos
		\[ \underbrace{\max W}_{Q_T} = \underbrace{\max W}_{\partial_P Q_T} \]

		\[ W(x,t) \leq \max\limits_{\partial_P Q_T} w \leq \max \{ \|f\|_\infty + \frac{M}{2}L^2, \|\alpha\|_\infty, \|\beta\|_\infty + \frac{ML^2}{2}\} \eqreason[\leq]{$M = \|F\|_\infty$} \dots \]

		Usando que el máximo de tres números positivos es siempre menor que su suma:
		\( \dots \leq \|f\|_\infty + \|\alpha\|_\infty + \|\beta\|_\infty + \|F\|_\infty \frac{L^2}{2} \label{eq:estimacion_a_priori_calor}\)

		\textbf{Conclusión}
		\[ u(x,t) \leq u(x,t) + \frac{M}{2}x^2 \leq \eqref{eq:estimacion_a_priori_calor} \]

		Análogamente $u(x,t) \geq … $

		Resultado: $|u(x,t)| \leq \|F\|_\infty \frac{L^2}{2} + … $

	\end{example}

	\obs Esta prueba \underline{solo funciona con contorno Dirichlet}.

%Clase  20-4-2016

	\newpage %FIXME: Puede romper el documento
	\subsection{Prueba alternativa del resultado de unicidad}
		\label{sec:Calor:Unicidad}

		Como decíamos antes, con el principio del máximo débil éramos capaces de dar un resultado de unicidad, pero sólo para unas condiciones de contorno muy concretas. Usaremos el método de la energía, multiplicando la ecuación por $u$ e integrando en $(0,L)$.

		Como siempre, tenemos dos soluciones $u_1, u_2$. Sea $u = u_1 - u_2$: queremos ver que $u = 0$. Hacemos la integral del método de la energía:
		\begin{align*}
			0 &= \int_0^L (u_t-u_{xx}) u \dif x = \int_0^L \underbracket{u u_t}_{\left(\frac{u^2}{2}\right)_t} \dif x - \underbracket{\int_0^L u u_{xx} \dif x}_{\text{por partes}} =  \\
			&= \left(\int_0^L \frac{u^2}{2}\dif x\right)_t - \underbracket{\left. u u_x \right|_{x=0}^L}_{A} + \int_0^L u^2_x \dif x
		\end{align*}

		Dado que $u$ es solución de la ``resta'' de dos problemas, las condiciones de contorno serán alguna de las siguientes:
		\[ \begin{cases}
			\text{Dirichlet: }	& u(0,t) = u(L,t) = 0 \\
			\text{Neumann: }	& u_x(0,t) = u_x(L,t) = 0 \\
			\text{Periódicas: } & u(0,t) = u(L,t) \\
								& u_x(0,t) = u_x(L,t) \\
			\text{Mixtas: }	& u(0,t) = 0 = u_x(L,t)
		\end{cases}\]

		Todas ellas hacen que $A$ sea cero, así que nos queda la siguiente igualdad:
		\( \od{}{t} \underbracket{\int_0^L \frac{u^2(x,t)}{2} \dif x}_{e(t)} = - \int_0^L u^2_x \dif x \label{eq:Calor:Unicidad:dt} \)

		Si tomamos $e(t) = \int_0^L \frac{u^2(x,t)}{2} \dif x$, lo que nos dice \eqref{eq:Calor:Unicidad:dt} es que $e' ≤ 0$, así que $e(t)$ es decreciente, y como además es la integral de un cuadrado es positiva: $e ≥ 0$. La cuestión es que si evaluamos en $t = 0$ aparecen las condiciones de contorno y nos sale cero: \[ e(0) = \int_0^L \frac{\overbracket{u^2(x,0)}^{=0}}{2} \dif x = 0 \] así que $e (t) = 0$. La única posibilidad entonces es que $u(x,t) = 0$ y por lo tanto $u_1 = u_2$: la solución es única.

		A modo de observación, si aplicásemos esto a dos problemas \[
		\begin{cases}
		u_t - u_{xx} = F \\
		u(x,0) = f_1(x)
		\end{cases} \qquad
		\begin{cases}
		v_t - v_{xx} = F \\
		v(x,0) = f_2(x)
		\end{cases} \] tendríamos otro resultado de dependencia continua  en $L^2([0,L])$ de los datos: \[ \int_{0}^L \abs{u(x,t) - v(x,t)}^2 \dif x ≤ \int_{0}^L \abs{f_1(x) - f_2(x)}^2 \dif x \]

	 \subsection{Problema de ``unicidad hacia atrás''}

		\begin{theorem}

			Supongamos que $u$ y $v$ son soluciones de la misma ecuación de calor:

			\[\begin{cases}
				u_t - u_{xx} = F(x,t) = v_t - v_{xx}, \quad x \in (0,L), t > 0 \\
				u(0,t) = h(t) = v(0,t) \\
				u(L,t) = g(t) = v(L,t)
			\end{cases}\]

			En $T > 0$, $u(x,T) = v(x,T)$. Entonces $u(x,t) = v(x,t), \forall t \in [0,T]$

		\end{theorem}

		\begin{proof}
			Consideramos
			\[\begin{cases}
				W = u-v\\
				W_t - W_{xx} = 0 \\
				W(0,t) = W(L,t) = 0\\
				W(x,T) = 0
			\end{cases}\]

			Queremos probar $W(x,t) = 0, t < T$

			Usando la {\bf energía}:
			\[ e(t) = \int_0^L \frac{W^2(x,t)}{2} dx \geq 0 \]
			Si $W(x,t) = 0$, entonces $e(t) = 0$. Derivando
			\( e'(t) = \int_0^L W W_t dx = \int_0^L W W_{xx} dx = \left. W W_x \right|_0^L - \int_0^L W^2_x dx \quad (\leq 0) \)
			\[ e''(t) = - \int^L_0 2 W_x W_{xt}\ dx = -2 \left\{ \left. W_x W_t \right|^L_{x=0} - \int_0^L W_{xx} W_t dx \right\} \]

			\[W(0,t)  = 0, \forall t \implies  W_t(0,t) = 0\quad \forall t \]
			\[W(L,t)  = 0, \forall t \implies  W_t(L,t) = 0\quad \forall t \]

			Entonces:
			\[ e'(t) = - \int_0^L W^2_x \dif x \]
			\[ e''(t) = 2 \int_0^L W_{xx} W_t \dif x \eqreason{$W_t=W_{xx}$} 2 \int_0^L W_{xx}^2 \dif x \]
			Luego tenemos que
			\[ e'(t) = \int_0^L W_x^2 \dif x = - \int_0^L W W_{xx} \dif x = - \pesc{W, W_{xx}}_{L^2(0,L)} \eqreason[\leq]{*} \left(\int_0^L W^2 \dif x \right)^{1/2} \left( \int_0^L W_{xx}^2 \dif x \right)^{1/2} \]

			\obs (*) Desigualdad de Cauchy-Swartz para producto escalar en $L^2$.

			\[ \left( \int_0^L W^2_x  \right)^{2} \leq \int_0^L W^2 \cdot \int_0^L W_{xx}^2 \]

			Entonces llegamos a:
			\[ (e'(t))^2  \leq 2 e(t) \cdot \frac{1}{2} e''(t) \quad\quad\quad e(T) = 0 \]

			Si $e(t) = 0$, entonces $W(x,t) = 0$. Supongamos $e(t_1) > 0$ para algún $t_1 \in (0,T)$

			\begin{minipage}[t]{\linewidth}
				\inputtikz{UnicidadAtras-E}
				\captionof{figure}{}
			\end{minipage}

			\[f(t) = \log (e(t))\]
			\[t_2 = \sup \set{ t \in [t_1,T] / e(t) > 0 \text{ en } [t_1,t) } \]
			\[f'(t) = \frac{e'(t)}{e(t)} \leq 0\]
			\[f''(t) = \frac{e''(t) e(t)- (e'(t))^2}{e^2(t)} \geq 0\]

			Entonces sabemos que $f$ es decreciente y convexa (en $[t_1,t2)$).\\
			Tomamos $t \in ( t_1 , t_2 )$.

			\begin{minipage}[t]{\linewidth}
				\inputtikz{UnicidadAtras-f}
				\captionof{figure}{}
			\end{minipage}

			Convexidad:
			\[f(\tau t_1 + (1-\tau)t) \leq \tau f(t_1) + (1-\tau) f(t), \tau \in (0,1)\]

			Y tomando exponenciales:
			\[e(\tau t_1 + (1-\tau)t) \leq e(t_1)^\tau e(t)^{1-\tau} \quad \forall t \in (t_1,t_2)\]

			hacemos tender $t$ a $t_2$ y obtenemos que $e(t)$ tiende a 0.
			\[ 0 \leq e(\tau t_1 + (1-\tau)t_2) \leq e(t_1)^\tau \cdot 0 = 0\]

			Donde $(\tau t_1 + (1-\tau)t_2)$ es un punto intermedio entre $(t_1,t_2)$.

			\[e(\tau t_1+(1-\tau)t_2) = 0\]

			Y esto es una contradicción con la definición de $t_2$.

		\end{proof}

	\subsection{Ecuación de difusión en todo el espacio}

		\[\begin{cases}
			u_t - \Delta u = 0 \text{ en } \real^n\\
			u(\bar{x},0) = f(\bar{x})
		\end{cases}\]

		Una de las primeras características que vamos a ver es cómo es la dispersión instantánea al infinito del calor. En estos sistemas, en cuanto el tiempo es positivo veremos que el calor concentrado en puntos se dispersa instantáneamente. La velocidad de propagación es infinita. Esto nos dará problemas con la unicidad, que solucionaremos añadiendo condiciones de contorno en el infinito. Condiciones mejores que ``el valor en el infinito es 0''. Intentaremos usar condiciones del tipo ``En el infinito las soluciones crecen como máximo como un polinomio''.

		Punto de partida: Solución fundamental (Núcleo de Gauss). Vamos a suponer que la temperatura inicial es finita. Y la normalizamos con una cantidad de calor = 1. Así buscaremos soluciones que conserven la cantidad total de calor.

		\[\begin{cases}
			u_t - \Delta u = 0 \text{ en } \real^n\\
			u(\bar{x},0) = f(\bar{x}) \\
			\int\limits_{\real^N} f(\bar{x}) d\bar{x} = 1
		\end{cases}\]

		\begin{example}[Dimensión espacial 1]
			Realizamos un cambio de escala:
			\[\begin{cases}
				x = \lambda y\\
				t = \mu z
			\end{cases}\]

			Queremos ver que valores de $\lambda$ y $\mu$ hacen que $v$ siga siendo solución.

			Veremos que no se pueden cambiar aleatoriamente y tenemos que respetar la relación entre tiempo y espacio $\lambda = \mu^2$ para realizar un cambio de variables adecuado. Y veremos que esto nos ayudará a pasar a una EDO.
		\end{example}

		% Clase 25-4-2016

		Vamos a estudiar ahora a fondo el problema, estudiando la ecuación
		\[u_t - \Delta u = 0 \qquad x \in \real^n,\, t > 0\]

		Buscaremos una solución particular, y además vamos a normalizar, esto es, hacer que el ``calor total'' sea 1:
		\( \int\limits_{\real^n} u(\bar{x},t) \dif \bar{x} = 1\; \forall t > 0 \label{eq:Calor:Normalizacion} \)


		Vamos a ir simplificando el problema. La primera simplificación que haremos será escribir $u$ como una función radial, esto es, $u = u(r)$ con $r^2 = x^2_1 + \dotsb  + x^2_n$. Sacando el laplaciano tenemos que
		\[ Δu =  u_{x_1 x_1} + u_{x_2 x_2} + \dotsb + u_{x_n x_n} = \dotsc = u_{x_r x_r} + \frac{n-1}{r}u_r \]

		Por el otro lado, aplicamos el cambio de variables a la normalización de \eqref{eq:Calor:Normalizacion}, y tenemos que
		\[ 1 = \int\limits_{\real^n}  u(\bar{x},t) \dif \bar{x} \eqreasonup{polares} \int_{\crc[n-1]} \int_0^\infty u(r,t) r^{n-1} \dif r \dif \omega = ω_n \int_0^\infty u(r,t) r^{n-1} \dif r \] con $ω_n$ la medida de la esfera $n$-dimensional de radio $1$.

		Con todo esto, llegamos a nuestro problema simplificado:
		\( \begin{cases}
			u_t - u_{rr} - \frac{n-1}{r}u_r  = 0\\
			\displaystyle\int_0^\infty u(r,t) r^{n-1} \dif r = \frac{1}{\omega_n}
		\end{cases} \label{eq:Calor:ProblemaSimplificado} \)

		Ahora aplicamos una idea feliz: vamos a estudiar qué efectos tienen los cambios de escala en nuestro problema. Dados dos factores $λ,μ$ de cambio de escala, hacemos la sustitución y estudiamos la solución ``reescalada'' $v$:
		\[\begin{cases}
			r = \lambda s\\
			t = \mu \tau
		\end{cases} \implies v(s,τ) = u(λs, μτ)\]


		Sacamos ahora las derivadas de nuestra nueva función, para prepararnos y sustituir en \eqref{eq:Calor:ProblemaSimplificado}:
		\begin{align*}
			v_\tau (s,\tau) &= u_t (\lambda s, \mu \tau) \cdot (\mu \tau)_{\tau} \\
				&= u_t(\lambda s, \mu \tau) \mu \\
				v_s(s,\tau) &= u_r(\lambda s, \mu \tau) \lambda \\
				v_{ss}(s,\tau) &= u_{rr} (\lambda s, \mu \tau) \lambda^2
		\end{align*}

		Ahora sustituimos en la ecuación diferencial, y vemos qué pasa:
		\begin{align*}
		v_\tau (s,\tau) - v_{ss}(s,\tau) - \frac{n-1}{s} v_s(s,\tau)
			&= \mu v_t(\lambda s, \mu \tau) - u_{rr}(\lambda s, \mu \tau) \lambda^2 - \frac{n-1}{\lambda s} \lambda^2 u_r(\lambda s, \mu \tau) = \\
			&= \mu u_t(\lambda s, \mu \tau) - \lambda^2 \left( u_{rr}(\lambda s, \mu \tau) - \frac{n-1}{\lambda s} u_r(\lambda s, \mu \tau)\right) = \\
			&= (\mu - \lambda^2) u_t(\lambda s, \mu \tau)
		\end{align*}

		A lo que llegamos es a que si $μ = λ^2$, la función $v$ sigue siendo solución del problema. Si los cambios no son independientes, tiene que haber alguna variable subyacente que nos dé ese cambio de escala.

		Tenemos
		\[ v(s, \tau) = C u(\lambda s, \lambda^2 \tau) \]

		Como buscamos soluciones que conserven la cantidad de calor, vamos a ajustar $C$ para que la integral sea constante:
		\begin{align*}
		\frac{1}{\omega_{n}} &= \int_0^\infty v(s, \tau) s^{n-1} \dif s
		= \int_0^\infty C u(\lambda s, \lambda^2 \tau) s^{n-1} \dif s = \\
		&\eqreason{cambio de variable $\lambda s = r$} \int_0^\infty C u(r, \lambda^2 \tau) \frac{r^{n-1}}{\lambda^{n-1}} \frac{\dif r}{\lambda}
		= \frac{C}{\lambda^n}  \underbrace{\int_0^\infty   u(r, \lambda^2\tau) r^{n-1} dr}_{= \frac{1}{\omega_n} (\forall \tau)}
		= \frac{C}{\lambda^n}\frac{1}{\omega_n}
		\end{align*}
		Luego $C = \lambda^n$. Así, nuestra solución reescalada ha de ser de la forma:
		\[ v(s,\tau) = \lambda^n u(\lambda s, \lambda^2 \tau)\]

		Con esto hemos llegado a que si existe una solución existen infinitas cambiando la $n$ en la fórmula anterior. Pero también hemos obtenido que las soluciones no solo deben ser $C^2$, sino que tienen que respetar estas restricciones. Ahora, con un espacio de funciones posibles menor vamos a intentar encontrarlas. Estudiamos qué ocurre cuando hacemos el siguiente cambio
		\[ \underbrace{v(s,1)}_{\text{una variable}} = \lambda^n u (\lambda s, \lambda^2) \]

		Tomando $\lambda^2 = t$, $\lambda s = r$ y $s = \frac{r}{\lambda} = \frac{r}{\sqrt{t}}$, tenemos

		\[ u(r,t) = \frac{1}{\lambda^n} v(s,1) = \frac{1}{t^{n/2}} v\left(\frac{r}{\sqrt{t}},1\right)\]

		Parece que hemos llegado a algo, pero ahora estamos haciendo variar $λ$. En cualquier caso, quizás podríamos buscar por funciones que sigan esa forma $$u(r,t) = \frac{1}{t^{n/2}} \Phi\left(\frac{r}{\sqrt{t}}\right), \text{ con }\Phi: \real \rightarrow \real$$

		Llegamos al {\bf problema}: Encontrar una función $\Phi$ (de una variable) tal que $u(r,t) = \frac{1}{t^{n/2}} \Phi(\frac{r}{\sqrt{t}})$ sea solución.

		Y este proceso se llama buscar \concept[Soluciones\IS autosemejantes]{soluciones autosemejantes}.

		\textbf{Notación: } $\xi = \frac{r}{\sqrt{t}}$, y $\xi_r = \frac{1}{\sqrt{t}}$, y $\xi_t = -\frac{1}{2} t^{-3/2} r$.

		\[ u_t = - \frac{n}{2} t^{-n/2-1} \Phi + t^{-n/2} \Phi' (\xi) \xi_t = -\frac{n}{2} t^{-n/2 - 1} \Phi(\xi) + t^{-n/2} \Phi'(\xi) (-\frac{1}{2}) \]
		\[ u_r = t^{-n/2} \phi' \xi_r = t^{-n/2} \phi' t^{-1/2} \]
		\[ u_{rr} = t^{-n/2 - 1/2} \phi'' t^{-1/2} \]

		\[ u_t - u_{rr} - \frac{n-1}{r}u_r = … = - t^{-n/2 - 1} \underbrace{\left\{ \Phi'' + \frac{n-1}{\xi}\Phi' + \frac{\xi}{2}\Phi' + \frac{n}{2}\Phi \right\}}_{\text{EDO}} \]

		{\bf Conclusión}: tenemos que resolver
		\[ \Phi'' + \frac{n-1}{\xi} \Phi'+ \frac{\xi}{2}\Phi' + \frac{n}{2}\Phi = 0\]

		En el caso $n = 1$:
		\[ \Phi'' + \underbrace{\frac{\xi}{2}\Phi' + \frac{1}{2}\Phi}_{\frac{1}{2} (\xi \Phi)'} = 0\]

		\[ \left[ \Phi' + \frac{1}{2} (\xi \Phi)  \right]' = 0 \implies \Phi' + \frac{1}{2} \xi \Phi = cte \]

		Si ponemos que la constante sea 0, es una EDO integrable\footnote{Si la constante no es 0, es una EDO lineal, con factor integrante $e^{- \int \frac{-1}{2} \xi d\xi}$}
		\[ \frac{\Phi'}{\Phi} = -\frac{1}{2} \xi\]
		\[ \Phi(\xi) = C e^{-\frac{\xi^2}{4}}\]

		Con $n=1$:
		\[ u(r,t) = t^{-\frac{1}{2}} \Phi(\frac{r}{\sqrt{t}}) = C t^{-1/2} e^{\frac{-r^2}{4t}}\]

		Para el caso $n \neq 1$ usamos el factor integrante $\mu = \xi^{n-1}$

		\[ \underbrace{\xi^{n-1} \Phi'' + (n-1) \xi^{n-2}}_{(\xi^{n-1}\Phi')'} \Phi' + \underbrace{\frac{1}{2}\xi^n \Phi' + \frac{1}{2} n \xi^{n-1} \Phi}_{(\frac{1}{2} \xi^n \Phi)'} = 0 \]

		\[ (\xi^{n-1} \Phi' + \frac{\xi^n}{2}\Phi)' = 0 \iff  \xi^{n-1} \Phi' + \frac{\xi^n}{2}\Phi = cte \]
		Tomando la constante como 0
		\[ \xi^{n-1} \Phi' = -
		\frac{\xi^n}{2}\Phi \iff \frac{\Phi'}{\Phi} = \frac{- \xi}{2} \iff \Phi = c e^{-\xi^2 / 4}\]


		{\bf Conclusión:}
			\[ u(r,t) = t^{-n/2} \Phi(\frac{r}{\sqrt{t}}) = t^{-\frac{n}{2}} C e^{-\frac{r^2}{4t}} \quad\text{ ({\bf Gaussiana})} \]

		\begin{figure}[hbtp]
			\begin{minipage}[t]{0.45\textwidth}
				\inputtikz{Nucleo-Gauss-t-pequeno}
			\end{minipage}
			\begin{minipage}[t]{0.45\textwidth}
				\inputtikz{Nucleo-Gauss-t-grande}
			\end{minipage}
			\caption{Aspecto que tiene el núcleo de Gauss}
		\end{figure}


		% Clase 26-4-2016
		Tenemos que ajustar el valor de $C$ para que
		\[
			1 = \frac{C}{t^{\rfrac{N}{2}}} \int_{\real^N} e^{-\frac{x_1^2+x_2^2+...+x_n^2}{4t}} dx = \frac{C}{t^{\rfrac{N}{2}}}\prod_{i=1}^n \int_{-∞}^{∞} e^{-\frac{x_i^2}{4t}} dx_i
		\]

		Haciendo el cambio de variables:
		\[
			z = \frac{x_i}{2\sqrt{t}}
		\]


		Obtenemos:
		\[
			\frac{C}{t^{\rfrac{N}{2}}} \left[ \int_{-∞}^{∞} e^{-z^2}2\sqrt{t} \dif z \right]^N = C 2^N \left( \int_{-∞}^{∞} e^{-z^2} \dif z \right)^N = C 2^N \pi^{N/2} \implies C = \frac{1}{(\sqrt{4 \pi})^N}
		\]


		Hemos llegado a la expresión del \concept{Núcleo\IS de Gauss}:
		\( G(x,t) = \frac{1}{(\sqrt{4πt})^N}\cdot e^{-\frac{\norm{\vx}^2}{4t}} \label{eq:NucleoGauss} \)

		Esto es una solución particular que tiene la curiosidad de que en $t=0$ no está definida.
		%
		Vamos a estudiar el núcleo de Gauss.

		\subsubsection{Propiedades del Núcleo de Gauss}\index{Propiedades!del núcleo de Gauss}

		\begin{itemize}
			\item $G(x,t) \geq 0$.
			\item $G(x,t)$ es par en $x_i$ (de hecho, es radial)
			\item $G(x,t)$ decreciente en $x_i>0$.
			\item Tomando el límite acercándonos a $t=0$, observamos:

			\[\lim_{t\to 0^+} G(x,t) = \begin{cases} 0&\text{si }\vec{x} ≠ 0 \\ ∞ & \text{si }\vx = 0\end{cases}\]

			\item $\displaystyle \int_{\real^n} G(x,t) \dif x = 1, \quad \forall t > 0$

			\item Estas 2 últimas propiedades se pueden escribir como que el núcleo de Gauss, converge en distribución a la delta de Dirac.

			\[
				G(x,t) \convs[][t][0^+] \delta_{x=0}
			\]
		\end{itemize}

		\newpage %FIXME: Puede romper el documento
		\begin{theorem}
		Sea $f$ una función continua y acotada. Sea \[u(x,t) = \int_{\real^n} G(\vx-\vy,t)f(\vy)d\vy\]

		\textbf{Entonces:}

		\begin{itemize}
			\item $u(x,t)\in C^{∞}$
			\item $u_t - Δu = 0, \vx \in \real^n\;,t>0$, es decir, es solución de la ecuación de difusión (o ecuación del calor).
			\item $\lim\limits_{t\to 0^+} u(x,t) = f(x)$ con convergencia puntual.
		\end{itemize}
		\end{theorem}

		\obs Tenemos un \textbf{efecto regularizante}.
		%
		Hemos llegado a soluciones $C^{∞}$ partiendo de cosas que no tendrían por qué serlo.

		Además, tenemos una \textbf{velocidad infinita}, es decir no existe $\vx \tlq u(\vx,ε) = 0$ cuando $ε\to 0$.
		%
		En un tiempo tan pequeño como queramos, encontramos que el calor del dato inicial se ha desplazado a cualquier punto.

		Vamos a justificarlo. Tenemos un objeto que integra 1, luego se comporta como una medida o distribución de probabilidad. La integral
		\[ u(x,y) = \int_{\real^n} f(y) \cdot G(x-y, t) \dif y  \ > 0 \quad \forall t, \forall  x\]
		mide la probabilidad de que cualquier partícula en y salte a x, mediante la suma de todas las probabilidades. El núcleo de Gauss permite saltos infinitos, pero con probabilidad muy, muy baja.

		% Supongamos que tenemos una pequeña cantidad de calor en $x=x_1, t=0$.
		%
		% La función solución $u(x,t)$ es siempre positiva. Al integrar el producto en $\vx = \vec{x_2}$ muy alejado de $\vec{x_1}$

		% \[
		%	\int_{\real^n} G(\vx_2-\vy,t)f(\vy)d\vy
		% \]

		% Comentarios ``útiles'':

		% \begin{equation}
		% 	\abs{\dpa{G}{x_i} (z,t)} \leq … \leq \frac{|x_i-y_i|+1}{2\sqrt{4πt}^N} e^{-\frac{\norm{x-y}(\norm{x-y}-2)}{4t}}
		% 	\label{eq:dejuan}
		% \end{equation}

		% Este paso clave demuestra que podemos pasar derivadas dentro de integrales, es decir:

		% \[
		% 	\dpa{u}{x_i} = \int_{\real^N} \dpa{G}{x_i} f
		% \]

		% Si tomamos más derivadas, en el término $|x_i-y_i|$ aparecería elevado a alguna potencia.
		% %
		% Independientemente de la potencia que aparezca, el argumento sigue siendo válido porque la exponencial negativa de \eqref{eq:dejuan} manda sobre cualquier polinomio.

		Como u es $C^\infty$, deberíamos saber calcular su derivada respecto de x. Pero, ¿podemos hacerlo?

		Para calcular $\pd{u}{x}$ tenemos por definición que
		\[ \lim_{h \to 0} \frac{u(\gor{x} + h e_i,t)-u(\gor{x},t)}{h} = \lim_{h \to 0} \int\limits_{\real^n} \frac{G(\gor{x}-\gor{y}+he_i,t)-G(\gor{x}-\gor{y})}{h} f(y) dy \]
		¿Podemos asegurar que el limite y la integral permutan? En primer lugar, no podemos aplicar el teorema de la convergencia monótona porque no sabemos si el signo de la integral es siempre el mismo o cambia.

		Luego debemos recurrir al siguiente teorema que vimos en TIM:

		\newpage %FIXME: Puede romper el documento
		\begin{theorem}[Convergencia\IS dominada]
			Si
			\begin{itemize}
				\item $ f_k \convs[ ][k][\infty] f \text{ puntualmente en } \Omega $
				\item $ | f_k (x) | \leq F(x), \forall x, \forall k $
				\item $ F $ integrable.
			\end{itemize}
			entonces
			\[ \lim_{k \to \infty} \int_\Omega f_k = \int_\Omega \lim_{k\to \infty} f_k = \int_\Omega f \]
		\end{theorem}
		\begin{proof}
		Lo que tenemos que estimar el cociente incremental, utilizando el Teorema del Valor Medio:
		\[ \frac{G(\gor{x}-\gor{y}+he_i,t)-G(\gor{x}-\gor{y},t)}{h} = \pd{G}{x_i}(z,t) \]
		Con $z$ un punto intermedio. Haciendo cuentas llegamos a
		\[ \pd{G}{x_i}(z,t) = \dots = \frac{-z_i}{2t} \frac{1}{(\sqrt{4 \pi t}) ^n} e^{-|z|^2 / 4t} \]
		Como $z$ es un punto intermedio entre $x-y$, e $x-y+h e_i$, lo podemos escribir como \[ z = x - y + \theta h e_i \quad \theta \in (0,1) \]
		luego
		\[ \left| \pd{G}{x_i} (z,t) \right| \leq \frac{|z|}{2t (\sqrt{4 \pi t})^n} e^{- \| z \|^2 / (4t)} \]

		Para acotar eso, tenemos que acotar $|z_i|$ por arriba y $|z|^2$ por abajo\footnote{para acotar por arriba una exponencial decreciente hay que encontrar el valor mínimo de su exponente}.
		\[ |z_i| \leq |x_i - y_i + \theta h e_i| \leq |x_i - y_i| + |\theta h e_i| \eqreason[\leq]{$h\leq1, \theta < 1$} |x_i - y_i| + 1 \]
		\begin{gather*}
		|z|^2 = \| x - y + \theta h e_i \|^2 = \pesc{x - y + \theta h e_i. x - y + \theta h e_i} = \dots =\\
		= \| x - y \|^2 + \| \theta h e_i \|^2 + 2 \pesc{x-y, \theta h e_i} \geq \| x - y\|^2 + 0 - 2 \| x - y\|
		\end{gather*}
		donde en la última desigualdad hemos usado Cauchy-Swartz para el producto escalar combinado con que $\theta h e_i \leq 1$, y que el cuadrado de una norma es positivo.

		Recordemos {\bf Cauchy-Swartz}\index{Desigualdad! de Cauchy-Swartz}:
		\[ -\|a\| \|b\| \leq |\pesc{a, b}| \leq \|a\| \|b\| \]

		Luego
		\[ \left| \pd{G}{x_i} (z,t) \right| \leq \frac{[x_i - y_i| + 1}{2t (\sqrt{4t \pi})^n} \cdot e^{\frac{-\| x-y \|(\| x-y \| - 2)}{4t} } \equiv \psi(y) \ \text{ x,t fijos; y derivable}\]

		Luego tenemos dentro de la integral $\psi(y) f(y)$, y sabemos que $f(y)$ está acotada.

		Necesitamos que $\psi$ decaiga a 0 en el infinito, ya que el dominio no está acotado, y que sea continua. Pero todo eso lo tenemos porque el término importante es la exponencial negativa, luego $\psi$ es integrable, luego podemos aplicar el teorema de la convergencia dominada .
		\end{proof}

		Para calcular la segunda derivada, en lugar de $|z_i|$ en la prueba aparece $z_i^2$. Luego el mismo argumento vale porque sigue dominando la exponencial negativa. Iterando el argumento hasta $z_i^n$ tenemos que $u \in C^\infty$.

		\obs Hemos utilizado que $t>0$

		El mismo argumento nos dice que $u_t - \Delta u = \int (G_z - \Delta G) f = 0$ . Pero, ¿recuperamos el dato inicial?

		\begin{proof}

			Queremos probar:
			\[ \int\limits_{\real^n} G(x-y,t) f(y) \dif y \convs[][t][0^+] f(x)\]

			\[ 0 \leq \left| \int\limits_{\real^n} G(x-y,t) f(y) \dif y - f(x) \int_{\real^n} G(x-y,t) \dif y \right| = \]

			\[ = \left| \int_{\real^n} G(x-y,t) (f(y)-f(x))\dif y \right| \eqreason[\leq]{$G \geq 0$} \int_{\real^n} G(x-y,t) |f(x) - f(y)| \dif y \]

			Aquí tenemos el mismo problema que con el núcleo de Poisson. Pero $f$ es continua, luego dado $\epsilon > 0$ encontramos $\delta$ tal que si $\|x-y\| < \delta$, entonces $|f(\bar{x})-f(\bar{y})| < \epsilon$. Dividimos la integral en dos trozos:
			\[ \int\limits_{\real^n} = \underbrace{\int\limits_{\|x-y\| < \delta}}_{(1)} + \underbrace{\int\limits_{\|x-y\|>\delta}}_{(2)}\]

			\[ (1) \leq \int\limits_{\|x-y\|\leq \delta} G \epsilon \eqreason[\leq]{$\int_{\real^n} G = 1$} \epsilon\]

			\[ (2): \int\limits_{\|x-y\|>\delta} G(x-y) \underbrace{| f(x) - f(y) |}_{\leq C \text{ ($f$ acotada)}} \dif y \leq C \int\limits_{\|x-y\| > \delta} \frac{1}{(\sqrt{4\pi t})^n} e^{-\frac{\|x-y\|^2}{4t}} \dif y \convs[exponencial][t][0^+] \epsilon\]
			Ya que la única forma de que el producto diverja es que $x-y=0$, pero ese caso está fuera de la región en la que estamos integrando.

			Entonces hay convergencia puntual:
			\[\int G(x-y,t) f(y) \dif y \convs[][t][0^+] f(x)\]

		\end{proof}

		\obs
				\begin{itemize}
					\item Si $f$ es continua puntualmente $\Rightarrow$ convergencia puntual (que acabamos de demostrar)
					\item Si $f$ es uniformenente contínua $\Rightarrow$ convergencia uniforme
					\item Si $f \in L^2 \Rightarrow u(x,t) \convs[L^2][t][0^+] f(x)$
				\end{itemize}


		% Clase 27-4-2016
		% Copiado por @gjulianm

		Ayer demostramos que teníamos convergencia a una función, pero el problema es que no sabemos si es solución única.

		Antes de eso vamos a ver el problema no homogéneo, es decir, con \[ \begin{cases}
		u_t - Δu = F(x,t) \\
		u(x,0) = f(x) \end{cases} \]

		El truco es el de siempre, el que ya usamos al jugar con la ecuación de onda. Asumimos de momento que $f$ y $F$ son tan regulares y acotadas como necesitemos.

		Para operar, descomponemos $u$ como suma de dos soluciones $v + w$, donde una se lleva el dato inicial y otra la no homogeneidad: \[
		\begin{cases} v_t - Δv = 0 \\ v(x,0) = f(x) \end{cases} \qquad \begin{cases} w_t - Δw = F(x,t) \\ w(x,0) = 0 \end{cases} \]

		Aplicamos ahora el principio de Duhamel que vimos en la \fref{sec:PrincipioDuhamel}. Fijamos un tiempo $s > 0$ y resolvemos el sistema \[ \begin{cases} Φ_t - ΔΦ = 0 \\ Φ(x,0) = F(x,s) \end{cases} \] con solución \[ Φ(x,t) = \int_{ℝ^N} G(x-y, t) F(y,s) \dif s \] del dato $F(x,s)$ en $t = 0$. Para ver la solución en $t = s$, hacemos la traslación: \[ Φ(x, t - s) = \int_{ℝ^N} G(x-y, t-s) F(y,s) \dif y \]

		Así, la solución $w(x,t)$ será la suma de los efectos de $F$ entre $0$ y $t$, luego \[ w(x,t) = \int_0^t Φ(x, t - s) \dif s = \int_0^t \int_{ℝ^N} G(x-y, t-s) F(y,s) \dif y \dif s\]

		Finalmente podemos hallar la solución al problema completo: \( u(x,t) = \int_{ℝ^N} G(x-y, t) f(y) \dif y + \int_0^t \int_{ℝ^N} G(x-y, t-s) F(y,s) \dif y \dif s \label{eq:Calor:SolucionNoHomogenea} \)

		De nuevo, nos encontramos con el problema de la unicidad. Tenemos $u_1$ y $u_2$ dos soluciones, así que consideramos la función $ψ = u_1 - u_2$ y buscamos soluciones no triviales al sistema \[ \begin{cases} ψ_t - Δψ = 0 \\ ψ(x,0) = 0 \end{cases} \]
		El problema es que las soluciones obtenidas no son razonables físicamente. Si nos restringimos a soluciones positivas y acotadas, la solución será única, pero hay monstruos, como por ejemplo el contraejemplo de Tychonoff.

		%Vuelta a @erpheus

		\subsection{Contraejemplo de Tijonov}
			También conocido como Tychonoff.  % Era ruso, y escribía su nombre en cirílico, así que cada autor lo escribe como mejor cree

			\[u_t - u_{xx} = 0\]

			En la dirección del tiempo tenemos solo una derivada (ecuación de orden uno) y solo necesitamos un dato inicial para fijar el problema.

			En la dirección de las x tenemos un problema de orden 2, por lo que hacen falta añadir dos datos si queremos fijar la $x$:

			\[\begin{cases}
				u_t-u_{xx} = 0 \\
				u(0,t) = g(t) \\
				u_x(0,t) = h(td)
			\end{cases}\]

			A Tijonov la cuenta le salio con $h(t)\equiv 0$, así que vamos a suponer eso.

			Tijonov decidió expresar $u(x,t)$ como desarrollo en forma de potencias: $$u(x,t) = \sum\limits_{k=0}^\infty a_k(t) x^k = a_0(t) + a_1(t)x + a_2(t)x^2 + …$$

			Que vamos a tratar como una serie formal:
			\[ g(t) = u(0,t) = a_0(t)\]
			\[ u_x(x,t) \qeq a_1(t) + 2a_2(t)x + 3a_3(t)x^2 + …\]
			\[ 0 = u_x(0,t) = a_1(t)\]
			\begin{align*}
				u_t(x,t) &= a'_0 + a'_1 x + a'_2x^2 + … \\
				u_x(x,t) &= a_1 + 2a_2x + 3a_3x^2 + … \\
				u_{xx}(x,t) &= 2a_2 + 3 \cdot 2 a_3 x + 4 \cdot 3 a_4 x^2 + …
			\end{align*}

			Para tener $u_t = u_{xx}$ igualamos los coeficientes de cada término en $x^j$.
			\[ a'_j(t) = (j+2)(j+1) a_{j+2} (t)\]
			\[a_1 \equiv 0 \Rightarrow a'_1 \equiv 0 \Rightarrow a_3 \equiv 0 \Rightarrow a'_3 \equiv 0 …\]

			Por lo que llegamos a que $a_{2n+1} = 0 \ \forall n$. Tenemos que hacer la cuenta con los pares de forma que no den 0 (no queremos soluciones triviales):
			\begin{align*}
				a_0 &= g \\
				g' &= a'_0 = 2 \cdot 1 a_2 (t) \Rightarrow a_2 = \frac{1}{2} g' \\
				\frac{1}{2}g'' &= a'_2 = 4 \cdot 3 a_4 (t) \Rightarrow a_4 = \frac{1}{4!} g'' \\
				\frac{1}{4!}g''' &= a'_4 = 6 \cdot 5 a_6 (t) \Rightarrow a_6 = \frac{1}{6!} g'''
			\end{align*}

			Y llegamos a la expresión general: $a_{2n} (t) = \frac{1}{(2n)!} g^{n)} (t)$
			\obs $g^{n)} \equiv$ derivada n-ésima

			Solución:
				\[ u(x,t) = \sum_{n=0}^\infty  \frac{1}{(2n)!} g^{n)} (t) x^{2n}\]

			\begin{figure}[hbtp]
				\begin{minipage}[t]{0.5\textwidth}
					\inputtikz{Tychonoff-XT}
				\end{minipage}
				\begin{minipage}[t]{0.5\textwidth}
					\inputtikz{Tychonoff-gT}
				\end{minipage}
				\caption{g debe ser $C^\infty$}
			\end{figure}

			¿Como elegimos $g$? Pues se puede demostrar que la $g$ que buscamos es
			\[ g(t) = \begin{cases}
				0,& t \leq 0 \\
				e^{-t^{-\alpha}},&  t>0
			\end{cases}\]
			\[ g \in C^\infty, g^{k)}(t) \equiv 0 \quad t \leq 0, g \not\equiv 0\]
			\obs El exponente $-t^{-\alpha}$ es un tecnicismo de la prueba.

		\subsection{Resultados (parciales) de unicidad}

			El desarrollo que hemos hecho en Tijonov no funciona bien en el infinito ya que tiene un término de la forma $x^{2n}$.

			\begin{theorem}[Unicidad de soluciones acotadas]
				\[ \begin{rcases}
					u_t - \Delta u = F \\
					u(x,0) = f
				\end{rcases} \quad \exists M \text{ tal que } |u(x,t)| < M, \forall x, t \]

				Si $u_1, u_2$ soluciones de este problema $\Rightarrow u_1 = u_2$
			\end{theorem}

			\begin{proof}
				Definimos $v = u_1 -u_2$ y tenemos el siguiente problema:

				\[\begin{cases}
					v_t - \Delta v = 0\\
					v(x,0) = 0
				\end{cases}  \quad\quad |v| < M\]

				Vamos a utilizar el principio de comparación, definimos
				\[ W(x,t) = \alpha \left(2t + \frac{\| x\|^2}{N} \right) \]
				ya que es fácil calcular su laplaciano y comprobar que cumple la ecuación de laplace, y además tenemos un $\alpha$ que podemos ajustar:
				\begin{gather*}
					\begin{rcases}
						W_t = 2\alpha\\
						W_{x_i} = \alpha \left(\frac{x_1^2 + \dots + x_n^2}{n} \right)_{x_i} = 2 \alpha \frac{x_i}{n} \\
						W_{x_i x_i} = \alpha \frac{2}{n}\\
						\Delta W = \sum W_{x_i x_i} = 2\alpha
					\end{rcases} \implies
					W_t - \Delta W = 0 \quad \forall \alpha
				\end{gather*}

				\begin{minipage}[m]{0.5 \textwidth}
					\inputtikz{Unicidad-Sol-Acotada-Cilindro-Parabolico}
				\end{minipage}
				\begin{minipage}[m]{0.5 \textwidth}
					\inputtikz{Unicidad-Sol-Acotada-Frontera-Parabolica}
				\end{minipage}

				En $t=0$:
				\[ \|\gor{x}\| \leq R \left. \begin{cases}
					W(x,0) = \alpha \frac{\|\gor{x}\|^2}{n}\\
					v(x,0) = 0
				\end{cases}\right\} \implies v \leq W \quad \forall \alpha \]

				\[ \|x\| = R \Rightarrow W(x,t) = \alpha(2t+\frac{R^2}{n}) \]

				Y entonces ¿podemos asegurar $W \geq v$ cuando $\|\gor{x}\| = R$?

				$v$ acotada $\implies v \leq M \eqreasonup[\leq]{?} \alpha (2t + \frac{R^2}{n})$, tomando $\frac{\alpha R^2}{n} > M$, por lo que $R^2 > \frac{nM}{\alpha}$

				Es decir, podemos comparar $v, W_\alpha$ en $Q_t = B_R(\gor{0}) \times [0,T]$, si $R^2 > \frac{nM}{\alpha}$.

				\begin{minipage}[m]{\textwidth}
					\inputtikz{Unicidad-Sol-Acotada-Region-Comparacion}
				\end{minipage}

				Conclusión: Fijamos un punto $(x_0,t_0)$ dentro de $Q_T$.
					\[v(x_0,t_0) \leq W(x_0,t_0) = \alpha (2t_0+ \frac{\|x_0\|^2}{n})\]

				Dado un punto cualquiera $(x_0,t_0)$ con $t_0 < T$ tenemos:
				\[ v(x_0,t_0) \leq \alpha \left(2 t_0 + \frac{\|x_0\|^2}{n} \right) \quad \forall \alpha\]

				Tomando $\alpha \rightarrow 0$:
				\[v(x_0,t_0) \leq 0 \implies v \equiv 0\]

				Por lo que las soluciones son iguales.

			\end{proof}

			\begin{theorem}
				\[\begin{cases}
					u_t - \Delta u = 0, x \in \real^n, t>0 \\
					|u(x,t)| \leq A e^{a \|x\|^2} \quad a,A > 0 \\
					u(x,0) = 0
				\end{cases}\]

				Entonces $u(x,t) \equiv 0$

			\end{theorem}

			\begin{proof}
				Vamos a demostrar algo más general:

				\[\begin{cases}
					v_t - \Delta v = 0 \\
					|v(x,t)| \leq A e^{a \|x\|^2} \\
					v(x,0) = g(x) \text{ (ACOTADA)}
				\end{cases}\]

				Es decir, que tendremos un principio del máximo: $v(x,t) \leq M \equiv \sup\limits_{x \in \real^n} g(x)$

				Queremos ponernos entonces en un caso acotado e ir ampliando los límites hasta que estemos en el caso no acotado.

				Definimos la función auxiliar: $$\Phi(x,t) = \frac{\mu}{(T+\epsilon -t)^{n/2}} e^{\frac{\|x\|^2}{4(T + \epsilon - t)}}$$ Hemos puesto $\epsilon$ en esta función para poder definir $\Phi(x,T)$.

				Gauss $\to t$, $\Phi \to c - t$, $\lambda = (c-t)^2$. Y podemos comprobar que $\Phi_t$ es solución:
				\[ \Phi_t - \Delta \Phi = 0\]

				Nuestro dominio acotado es $Q_t = \{ \|x\| \leq R \} \times [0,T]$.

				Definimos:
				\[ W(x,t) = v(x,t) - \Phi(x,t) \]
				\[ W_t - \Delta W = 0\]

				Estudiamos $W$ en la frontera parabólica $\partial_p Q_T$.


				\begin{minipage}[m]{\textwidth}
					\vspace{15pt}
					\inputtikz{Teorema-Unicidad-Frontera-Parabolica}
					\captionof{figure}{Frontera parabólica de $Q_T$}
				\end{minipage}

				En $\set{(x,0), \|x\| < R}$
				\[ W(x,0) = v(x,0) - \Phi(x,0) = g(x) - \Phi(x,0) \leq g(x) \]

				En $\set{(x,t), \|x\| = R, t \in [0,T]}$
				\[ W(x,t) = v(x,t) - \Phi(x,t) = v(x,t) - \frac{u}{(T + \epsilon - t)^{n/2}} e^{\frac{R^2}{4(T+\epsilon-t)}} \leq \]
				\( \leq Ae^{aR^2} - \frac{\mu}{(T + \epsilon -t)^{n/2}} e^{\frac{R^2}{4(T + \epsilon - t)}} \label{eq:desigualdad_frontera_prueba_1} \)

				Vamos a quitarnos la ``t'' en ese sumando negativo. Si observamos
				\[ F(s) = \frac{1}{(c-s)^{n/2}} e^{\frac{B}{c-s}}\]
				se puede comprobar que $F'(s) > 0$ cuando $s\in(0,c)$, luego $F$ es creciente en ese intervalo.
				Luego tenemos $F(0) \leq F \leq F(c)$. Por el signo menos, lo que nos interesa es la desigualdad $F(0) \leq F$.

				Luego
				\[ la \fref{eq:desigualdad_frontera_prueba_1} \leq e^{aR^2} \left\{A-\frac{\mu}{(T+\epsilon)^{n/2}} e^{R^2 \left(\frac{1}{4(T+\epsilon)}-a \right)} \right\} \equiv (*)\eqexpl[\leq]{?} \sup(g) \]

				Las ideas para controlar esa última desigualdad son
				\begin{itemize}
					\item Elegimos $T$ lo bastante pequeño como para que $\frac{1}{4(t+\epsilon)}-a > 0$. Por ejemplo, $T = \frac{1}{8a}$, $\epsilon < \frac{1}{8a}$.
					\item Hay que tomar R lo bastante grande como para que la exponencial negativa domine. Si hacemos $R \to \infty$, la exponencial tiende a $- \infty$, luego hay un $T$ a partir del cual $(*)$ es menor que $sup(g)$.
				\end{itemize}

				Entonces $(*) \to - \infty$

				\textbf{Conclusión:} $T = \frac{1}{8a}$, $R > R_0 \implies W(x,t) \leq \sup(g) \equiv M$.

				El principio del máximo en $Q_T$ nos lleva a una contradicción. Por lo que hemos demostrado que en toda la banda de anchura temporal $(\frac{1}{8a})$, $W(x,t) \leq M$.

				Teníamos que
				\[ W(x,t) = v(x,t) - \frac{\mu}{(T + \epsilon -t)^{n/2}} e^{\frac{\|x\|^2}{4(T + \epsilon - t)}} \quad \forall \mu > 0 \]

				Haciendo tender $\mu$ a 0 entonces $v(x,t) \leq M, x \in \real^n$, $t \in [0,\frac{1}{8a}]$

				Ahora miramos el mismo problema empezando en $\frac{1}{8a}$:

				\[\begin{cases}
					(v_2)_t - \Delta v_2 = 0 \\
					|v_2(x,t)| \leq A e^{a\|x\|^2} \\
					v_2(x,\frac{1}{8a}) = v(x,\frac{1}{8a})
				\end{cases}\]


				Tenemos un problema con las mismas constantes del anterior, por lo que podemos iterar, empezando en $\frac{2}{8a}$ esta vez. E iterando el argumento llegamos a donde queramos avanzando $\frac{1}{8a}$ en cada paso.

			\end{proof}

			\begin{theorem}[Teorema\IS de Widder] (1944)

				Dadas las condiciones:
				\[\begin{cases}
					u_t - \Delta u = 0, x \in \real^n, t > 0 \\
					u(x,0) = f(x) \geq 0 \\
					u(x,t) \geq 0 \quad \forall x \forall t \\
					(u \in C^1 \text{ en } t, C^2 \text{ en } x)
				\end{cases} \implies \text{ Si } u_1,u_2 \text{ soluciones, entonces } u_1 \equiv u_2\]
			\end{theorem}

			\begin{proof}

				\proofpart{paso 1: convergencia dominada}
					\[v(x,t) = \int_0^t u(x,s) ds\]

					\[ \begin{rcases}
						v_t - \Delta v = 0\\
						v \geq 0\\
						v_t \geq 0, v \text{ creciente en } t\\
						-\Delta v \leq 0 \text{ para t fijo}
					\end{rcases} \quad \implies v \equiv 0 \implies u \equiv 0
					\]

				\proofpart{paso 2: teorema}

					Supongamos que $u_t - \Delta u = 0, x \in \real^n, t > 0$; $u$ es $C^1$ en $t$, $C^2$ en $x$, y $u \geq 0$. Entonces

					\[ \underbrace{\int\limits_{\real^n} G(x-y,t) \ u(y,0) \dif y}_{u_G} \leq u(x,t) \]

					\obs Sabemos que hay más soluciones (eg: contraejemplo de Tychonov), pero $u_G$ es la {\bf más pequeña}.

				\proofpart{paso 3}

					Suponiendo que tenemos: \[
					\begin{cases}
						u_t - \Delta u = 0, x \in \real^n, t > 0\\
						u \text{ es } C^1 \text{ en } t, C^2 \text{ en } x\\
						u \geq 0\\
						u(x,0) = 0
					\end{cases}\]

					Entonces $|u(x,t)| \leq A e^{a\|x\|^2}$ y teniendo en cuenta el paso 1: $u \equiv 0$.

				\newpage % FIXME: puede romper el documento
				\proofpart{final}

				Todavía no hemos terminado la demostración totalmente ya que no podemos afirmar que la diferencia entre $u$ y $v$ sea siempre positiva.

				Teniendo en cuenta el paso 2: $u$ solución $\implies u \geq u_G$. Por lo tanto $u - u_G \geq 0$. Finalmente por el paso tres llegamos a $u \equiv u_G$.

				{\bf Conclusión:} Cualquier solución es igual a la de Gauss.

			\end{proof}


\section*{Comentario para las hojas de ejercicios}

Dado un problema como:

\[\begin{cases}
	u_t - K \Delta u = 0, x \in \real^n, t > 0 \\
	u(x,0) = f(x)
\end{cases}\]

1) Rehacer el cálculo de núcleos de Gauss teniendo en cuenta la constante.

2) Cambio de variables:

\begin{gather*}
	v(x,s) = u(x,cs)\\
	\Delta v(x,s) = \Delta u(x,cs)\\
	v_s(x,s) = u_t (x,cs) C
\end{gather*}

\[ v_s (x,s) - \Delta v(x,s) = c u_t (x,cs) - \Delta u(x,cs) = c u_t (x, cs) - \frac{1}{k} u_t (x,cs) \]
\[ u_t - k \Delta u = 0 \Rightarrow - \Delta u = - \frac{1}{k} u_t = (c - \frac{1}{k}) u_t(x,cs) \to C = \frac{1}{k}\]
\[ v(x,s) = u(x,\frac{s}{k}) \text{ es solución de } v_s - \Delta v = 0\]
Con lo que llegamos a que $ v(x,0) = u(x,0) = f(x)$.

Hemos demostrado que sea $v(x,s) = u(x,\frac{s}{k})$. Entonces $v_s - \Delta v = 0 \Leftrightarrow u_t - k \Delta u = 0$

\[ v(x,s) = \int\limits_{\real^n} G(x-y,s) f(y) dy = \int\limits_{\real^n} \frac{1}{(\sqrt{4\pi s})^n} e^{-\frac{\|x-y\|^2}{4s}} f(y) dy \]
\[ u(x,\frac{s}{k}) = \int\limits_{\real^n} \frac{1}{(\sqrt{4\pi s})^n} e^{-\frac{\|x-y\|^2}{4s}} f(y) dy \]

Como tebemos $\frac{s}{k} = t$:
\[ u(x,t) = \int\limits_{\real^n} \frac{1}{(\sqrt{4\pi kt})^n} e^{-\frac{\|x-y\|^2}{4kt}} f(y) dy\]





